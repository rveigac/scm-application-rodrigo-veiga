---
title: "Final Project Research Design"
author: "Rodrigo Veiga"

institute: "University of Pennsylvania"
date: last-modified
toc: true

bibliography: References.bib

format: 
  html:
    self-contained: true

editor: source
---

```{r libraries, include=FALSE}
#libraries
library(ggplot2)
library(ggthemes)
library(readr)
library(ggdag)
library(tidyverse)
library(gt)
library(modelsummary)

#other libraries that support my style of coding
library(tidyverse)
library(rio)
#library(tidylog)
library(gapminder)
library(janitor)
library(kableExtra)
```

## 1- Research Question

In late 2009, The Economist published a cover featuring Rio de Janeiro’s Cristo Redentor midway through a meteoric launch^[See https://www.economist.com/leaders/2009/11/12/brazil-takes-off]. Less than four years later, it again published a cover featuring Brazil’s Cristo, but this time, it was pictured as an out-of-control rocket in a spectacular crash^[See https://www.economist.com/leaders/2013/09/27/has-brazil-blown-it]. What happened in the meantime? What could have gone so wrong in such a short period? This story, as many others within the cloudy overlap between economic policy and electoral politics, is not so straightforward.

This project proposes that such a story should be revised in two ways. First, 2009-2013 is the wrong timeline. We should rather focus on the 2003-2016 period, during which the Workers Party uninterruptedly controlled the Federal Execute branch. Second, one must not jump to conclusions before concomitantly considering (1) the economic, political, and policy-making events of the period; and (2) a thorough empirical analysis of the data.

With that in mind, my main research question is: 

**Did the New Economic Matrix, instituted by the Workers Party starting in 2006, positively or negatively impact GDP per capita in Brazil?**

This question builds upon a wide range of existing research on the topic. My goal is to add to the discussion from two papers that have used the same empirical method I will imply, albeit with relevant differences in the research question and methodological setting than mine. @carrasco2014decada applies the synthetic control method (SCM) to quantify the impact of the Workers Party tenure on economic development in Brazil. They apply the start of President Lula's first presidential administration as the event of interest and set 2003 as the intervention year. The authors argue that the Party had a negative impact of about 12% in Brazil's GDP per capita as of 2012. @balassiano2018recessao attempts to quantify the impact that domestic factors had on the severity of the Brazilian recession of 2014-2016. The author found evidence that the substantial deterioration of the Brazilian economy was more a result of internal than external factors.

While the studies mentioned above are informative, their results are sub-optimal because their synthetic controls fall short of representing credible counterfactuals to the trend of GDP per capita in Brazil. State-of-the-art literature on the SCM (cited below) asserts that you must have an event that characterizes a clear, traceable break separating before and after scenarios. I argue that Carrasco's intervention year (2003) is not ideal because there are no major shifts in economic policymaking during the first three years of Lula's first term as President. There are also no major shifts, breaks or shocks in Balassiano's choice of intervention year (2013).

Extensive research on economic policy in Brazil presents a clear consensus and points us to the most appropriate setting for the application of synthetic controls. Several different authors employing a myriad of methods (@abreu2014ordem, @barbosa2014desaceleraccao, @borges2016bad, @pessoa2017debate, among others) affirm that a major shift in economic policy (from a macro, micro, monetary, fiscal, and public policy perspectives) happened in early 2006, when a new Finance Minister was appointed by the presidential administration. The shift was so prominent that both the government and the researchers named it as the New Economic Matrix (NEM). 

I will provide details of what were the specific policies within the New Economic Matrix in my final submission.

## 2- Hypothesis

My main hypothesis is that we will observe a greater underperfomance of Brazil's GDP per capita trend in comparison to the counterfactual (the synthetic control) than the 12% found in @carrasco2014decada This hypothesis is based on three main arguments. 

First, my analysis will be based on a dataset that has data for the recent Brazilian recession of 2014-2016, which is not present in the main results from Carrasco, since their dataset only goes up to 2012. 

Second, I hypothesize that we collective work that has been done to methodically map the event that marked the dawn of a new era in economic policymaking in Brazil will pay off in terms of providing more robust and trustworthy results for the synthetic control. 

Third, building upon the previous two arguments, it has been shown that the NEM had negative effects in the Brazilian economy. @borges2017debate uses three different methodological approaches to argue that – both domestic and external – factors exogenous to the Brazilian economy are responsible for approximately 50% of the economic downturn in the 2012 - 2016 period. While he demonstrates support for some policies packaged within the NEM and argues that the deceleration in potential growth can be tied to several factors that are exogenous to (independent of) economic policy, the author accepts that most of the remaining 50% are caused by domestic economic policy mistakes of the NEM (not **all** of the remaining 50%, since the author leaves room for measurement errors there).

## 3- Data, sample, and visualization

### Data and Sample

My unit of analysis will be a country-year panel. I downloaded my dataset from the World Bank's World Development Indicators (WDI). While the WB produces a lot of the data points in the WDI dataset, the OECD, IMF, UN, and ILO are responsible for some of the variables I downloaded. I also merged my original dataset with additional data points on government debt (from the IMF) and terms of trade (from the OECD). My raw dataset is composed of 35 countries and 72 variables over the 1970-2022 period. After extensive research and analysis, I have decided that my synthetic control model will be based on a sample of 20 countries and 8 variables over the 1990-2018 period. Details are provided below.

**Country of interest:** Brazil.

**Country pool** (that will be fed into the model to create the synthetic control): Bolivia, Bulgaria, Chile, China, Colombia, Costa Rica, Ecuador, Egypt, India, Iran, Mexico, Pakistan, Paraguay, Peru, Poland, South Africa, Türkiye, Ukraine, Uruguay.

**Variable of interest:** GDP per capita, PPP (constant 2017 international $).

**Covariates:** Agriculture, forestry, and fishing, value added (% of GDP); GDP per capita, PPP (constant 2017 international $); Gross capital formation (% of GDP); Industry (including construction), value added (% of GDP); Inflation, consumer prices (annual %); Net barter terms of trade index (2015 = 100); Trade Openness (% of GDP) (defined as Exports of goods and services (% of GDP) + Imports of goods and services (% of GDP), following @abadie2015comparative and the concept of additive indexes we learned in class); and Unemployment, total (% of total labor force) (national estimate).

**Pre-intervention period**: 1990 - 2005

**Post-intervention period**: 2006 (intervention year) - 2018 (the last year before Jair Bolsonaro, the winner of the 2018 Presidential Elections, took over as President).

**Intervention of interest:** The change in Finance Minister in early 2006. Antônio Palocci was replaced by Guido Mantega, setting off the policy changes that encompass what is defined as the New Economic Matrix.

### Preliminary Visualization

I created two preliminary figures that trace Brazilian GDP per Capita in comparison with selected countries. The goal of this preliminary visualization exercise is twofold. One, to investigate whether Brazil actually took off in the early 2000s, as the 2009 cover for The Economist affirmed. Two, to make the case for why the synthetic control method is the best empirical tool available to help me shed light upon my research question.

```{r graph 1 prep, include=FALSE}
####Loading and cleaning original dataset####

#loading libraries
library(tidyr)
library(foreign)
library(Synth) 
library(xtable)
library(tidyverse)
library(rio)
#library(tidylog)
library(readxl)
library(ggthemes)
library(gridExtra)

setwd("/Users/rodrigo/Documents/GitHub/scm-application-rodrigo-veiga")

data.raw <- read.csv("data/Data.raw.csv")

#datasets to be merged with the cleaned version of the one above:
data.ttrade <- read.csv("data/Indonesia terms of trade.csv")


#the plan is to clean the dataset and make it look like the one named "d" in the rep.r file under the CODING EXAMPLES folder
#I will use data.raw as my starting point. once the new dataset based on data.raw looks similar to "d"'s format I will add the information on data.deficit as a new column

data.clean <- data.raw

#--
#1. Renaming country column using colnames()
colnames(data.clean)[colnames(data.clean) == "Country.Code"] <- "country"

#--
#2. Renaming country name column using colnames()
colnames(data.clean)[colnames(data.clean) == "Country.Name"] <- "index"

#--
#3.Changing entries of the new index column to numbers (based on "d" format)
data.clean$index[data.clean$index == "Argentina"] <- 1
data.clean$index[data.clean$index == "Australia"] <- 2
data.clean$index[data.clean$index == "Bolivia"] <- 3
data.clean$index[data.clean$index == "Brazil"] <- 4
data.clean$index[data.clean$index == "Bulgaria"] <- 5
data.clean$index[data.clean$index == "Chile"] <- 6
data.clean$index[data.clean$index == "China"] <- 7
data.clean$index[data.clean$index == "Colombia"] <- 8
data.clean$index[data.clean$index == "Costa Rica"] <- 9
data.clean$index[data.clean$index == "Ecuador"] <- 10
data.clean$index[data.clean$index == "Egypt, Arab Rep."] <- 11
data.clean$index[data.clean$index == "Hungary"] <- 12
data.clean$index[data.clean$index == "India"] <- 13
data.clean$index[data.clean$index == "Indonesia"] <- 14
data.clean$index[data.clean$index == "Iran, Islamic Rep."] <- 15
data.clean$index[data.clean$index == "Lithuania"] <- 16
data.clean$index[data.clean$index == "Malaysia"] <- 17
data.clean$index[data.clean$index == "Mexico"] <- 18
data.clean$index[data.clean$index == "Pakistan"] <- 19
data.clean$index[data.clean$index == "Paraguay"] <- 20
data.clean$index[data.clean$index == "Peru"] <- 21
data.clean$index[data.clean$index == "Philippines"] <- 22
data.clean$index[data.clean$index == "Poland"] <- 23
data.clean$index[data.clean$index == "Romania"] <- 24
data.clean$index[data.clean$index == "Russian Federation"] <- 25
data.clean$index[data.clean$index == "South Africa"] <- 26
data.clean$index[data.clean$index == "Thailand"] <- 27
data.clean$index[data.clean$index == "Turkiye"] <- 28
data.clean$index[data.clean$index == "Ukraine"] <- 29
data.clean$index[data.clean$index == "United States"] <- 30
data.clean$index[data.clean$index == "Uruguay"] <- 31
data.clean$index[data.clean$index == "Venezuela, RB"] <- 32

#--
#4. now I need to reshape my dataset. It is originally in the wide format (where each year has its 
#own column) and I want it to be on a long format, where I have a single column for years and 
#a separate column for each variable type.

#4.1 let's first rename our year columns
# Renaming year column using colnames() and sub()
colnames(data.clean) <- sub("^X(\\d{4})\\.\\.YR\\1\\.$", "\\1", colnames(data.clean))

#4.2 deleting the series.code column
data.clean.nocode <- subset(data.clean, select = -Series.Code)

#4.3 transforming each column year into a column that contains the years
data.clean.long <- gather(data.clean.nocode, key = "Year", value = "Value", "1970":"2022")

#4.4 adjusting dataset above to make "" entries in country column to be NA entries
data.clean.long$country <- replace(data.clean.long$country, data.clean.long$country == "", NA)

#4.5 adjusting dataset above to remove rows that have NA in the country column
data.clean.long2 <- data.clean.long[complete.cases(data.clean.long$country), ]

#4.6 transforming the column series.name into several columns, each representing one variable
data.clean.finalish <- spread(data.clean.long2,Series.Name,Value) #now this dataset has the same format as the one used by abadie (dataset "d")

#--

#5. Making my dataset have NAs in empty entries

data.clean.finalish[data.clean.finalish == ".."] <- NA

#--

#6. Subsetting variables to be used in this version

data.scm.v4.vars <- data.clean.finalish[, c("index", 
                                            "country", 
                                            "Year", 
                                            "Agriculture, forestry, and fishing, value added (% of GDP)", 
                                            "Central government debt, total (% of GDP)", 
                                            "Exports of goods and services (constant 2015 US$)",
                                            "Exports of goods and services (% of GDP)", #will use exports and imports as % of gdp summed in a variable called trade openness
                                            "GDP per capita, PPP (constant 2017 international $)", 
                                            "Gross capital formation (% of GDP)", 
                                            "Imports of goods and services (constant 2015 US$)",
                                            "Imports of goods and services (% of GDP)", #will use exports and imports as % of gdp summed in a variable called trade openness
                                            "Industry (including construction), value added (% of GDP)", 
                                            "Inflation, consumer prices (annual %)", 
                                            "Net barter terms of trade index (2015 = 100)", 
                                            "Official exchange rate (LCU per US$, period average)", 
                                            "Unemployment, total (% of total labor force) (national estimate)")]

#6.1 renaming columns

data.scm.v4.vars <- data.scm.v4.vars %>%
  rename(
    year = Year,
    agva = "Agriculture, forestry, and fishing, value added (% of GDP)",
    debt = "Central government debt, total (% of GDP)",
    exportsv2 = "Exports of goods and services (constant 2015 US$)",
    exportspctv4 = `Exports of goods and services (% of GDP)`,
    gdpcv2 = "GDP per capita, PPP (constant 2017 international $)",
    gcfv4 = "Gross capital formation (% of GDP)",
    importsv2 = "Imports of goods and services (constant 2015 US$)",
    importspctv4 = `Imports of goods and services (% of GDP)`,
    indva = "Industry (including construction), value added (% of GDP)",
    infrate = "Inflation, consumer prices (annual %)",
    termstrade = "Net barter terms of trade index (2015 = 100)",
    exrate = "Official exchange rate (LCU per US$, period average)",
    unempv2 = "Unemployment, total (% of total labor force) (national estimate)"
  ) 

#6.2 making stuff numeric
conv_cols <- c("index",
               "year",
               "agva",
               "debt",
               "exportsv2",
               "exportspctv4",
               "gdpcv2",
               "gcfv4",
               "importsv2",
               "importspctv4",
               "indva",
               "infrate",
               "termstrade",
               "exrate",
               "unempv2"
)

data.scm.v4.vars <- data.scm.v4.vars %>% 
  mutate_at(conv_cols, as.numeric)

#6.3 Following SCM best practices and Abadie (2015), here I create the variable trade openness
#Trade Openness: Exports plus Imports as percentage of GDP
data.scm.v4.vars <- data.scm.v4.vars %>% 
  mutate(tradeop = exportspctv4 + importspctv4)

#--

#7 Merging datasets

#7.1 Adding updated Indonesia terms of trade info
data.ttrade.merge <- data.ttrade %>% 
  select(LOCATION, TIME, Value)

data.scm.v4.vars.step7 <- data.scm.v4.vars %>%
  mutate(termstrade = ifelse(country == "IDN" & year >= 1993 & year <= 2022,
                             data.ttrade.merge$Value[match(year, data.ttrade.merge$TIME)],
                             termstrade))
#now the dataset has incorporated all the updated data and is ready for analysis

#--

#8. Getting data ready for graphs

#subsetting only variable I will use for graphs here (gdpcv2)
data.intro.graphs <- data.scm.v4.vars.step7 %>% 
  select(index, country, year, gdpcv2)

#subsetting into Brazil, Chile, Mexico, Argentina, and LaTam

#Brazil
data.brazil <- data.intro.graphs %>% 
  filter(country == "BRA")

#Chile
data.chile <- data.intro.graphs %>% 
  filter(country == "CHL")

#Mexico
data.mex <- data.intro.graphs %>% 
  filter(country == "MEX")

#Argentina
data.arg <- data.intro.graphs %>% 
  filter(country == "ARG")

##LaTam##
#selecting countries
data.latam <- data.intro.graphs %>%
  filter(country %in% c("ARG",
                        "BOL", 
                        "BRA", 
                        "CHL", 
                        "COL", 
                        "CRI", 
                        "ECU", 
                        "MEX", 
                        "PRY", 
                        "PER",
                        "URY")) #original dataset has no information for venezuela

#creating average
data.lat.avg <- aggregate(gdpcv2 ~ year, data = data.latam, FUN = mean, na.rm = TRUE) #first year w/o na is 1990

#subsetting others to start from 1990
data.brazil.90 <- data.brazil %>% 
  filter(year >= 1990)

data.chile.90 <- data.chile %>% 
  filter(year >= 1990)

data.mex.90 <- data.mex %>% 
  filter(year >= 1990)

data.arg.90 <- data.arg %>% 
  filter(year >= 1990)

#creating one dataset out of that info
final.data.intro.graphs <- data.lat.avg %>% 
  rename(gdp.lat.avg = gdpcv2)

#subsetting country-specific datasets
br.tobind <- data.brazil.90 %>% 
  select(gdpcv2) %>% 
  rename(gdp.bra = gdpcv2)

chile.tobind <- data.chile.90 %>% 
  select(gdpcv2) %>% 
  rename(gdp.chile = gdpcv2)

arg.tobind <- data.arg.90 %>% 
  select(gdpcv2) %>% 
  rename(gdp.arg = gdpcv2)

mex.tobind <- data.mex.90 %>% 
  select(gdpcv2) %>% 
  rename(gdp.mex = gdpcv2)

#binding them into dataset I will use for the graphs
this.for.graph <- cbind(final.data.intro.graphs, br.tobind, chile.tobind, arg.tobind, mex.tobind)

#pivoting data in long format
gdp_data_long <- this.for.graph %>%
  pivot_longer(cols = starts_with("gdp"), names_to = "country", values_to = "gdp.per.capita")

#--

#9. PLOT OF GDP PER CAPITA OVER TIME 2000-2016 (Figure 1)
gdp_data_long_0016 <- gdp_data_long %>% 
  filter(year >= 2000 & year <= 2016)

plot.0016.gdp <- ggplot(gdp_data_long_0016, aes(x = year, y = gdp.per.capita, color = country)) +
  geom_line() +
  labs(title = "GDP Per Capita for Selected Countries",
       x = "Year",
       y = "GDP per capita, PPP (2017 int. $)",
       color = "Country") +
  scale_color_manual(values = c("lightblue", "green", "firebrick", "purple", "orange"), 
                     name = "", 
                     breaks = c("gdp.arg", "gdp.bra", "gdp.chile", "gdp.lat.avg", "gdp.mex"),
                     labels = c("Argentina", "Brazil", "Chile", "LaTam Avg.", "Mexico")) +
  theme_base() +
  theme(axis.title = element_text(size = 12), plot.title = element_text(size = 15)) +
  scale_x_continuous(breaks = unique(gdp_data_long_0016$year)) +
  theme(axis.text.x = element_text(size = 8), axis.text.y = element_text(size = 9)) +
  theme(legend.position = "bottom", plot.title.position = "panel") +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5), legend.text = element_text(size = 11))

```

```{r graph 1, echo=FALSE, results='markup', fig.cap='Figure 1 (Latin American average is defined as the average values for Argentina, Bolivia, Brazil, Chile, Colombia, Costa Rica, Ecuador, Mexico, Paraguay, Peru, and Uruguay)'}
plot.0016.gdp
```

In Figure 1, we see that Brazil starts the 2000s with GDP per capita levels significantly below that of Argentina, Chile, and Mexico. Brazil spends most of the following 16 years relatively in line with the Latin American average. It is never able to catch up with its selected peers (although it does get closer to Mexico). This is informative, but not a good base for comparison. We can try to normalize this figure and focus on the 2003-2016 timeline during which the Workers Party uninterruptedly held the Presidency in Brazil.


```{r graph 2 prep, include=FALSE}
#10. GROWTH TRENDS FOR SELECTED COUNTRIES (base 100 graph) (FIGURE 2)

#filtering years in the graph
gdp_data_long_0316 <- gdp_data_long %>% 
  filter(year >= 2003 & year <= 2016)

#normalizing base

#for latam avg
gdp_data_long_0316.latnorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.lat.avg") 

gdp_data_long_0316.latnorm <- gdp_data_long_0316.latnorm %>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.latnorm$gdp.per.capita[1])*100)

#for brazil
gdp_data_long_0316.branorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.bra") 

gdp_data_long_0316.branorm <- gdp_data_long_0316.branorm %>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.branorm$gdp.per.capita[1])*100)

#for chile
gdp_data_long_0316.chinorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.chile") 

gdp_data_long_0316.chinorm <- gdp_data_long_0316.chinorm%>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.chinorm$gdp.per.capita[1])*100)

#for argentina
gdp_data_long_0316.argnorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.arg") 

gdp_data_long_0316.argnorm <- gdp_data_long_0316.argnorm %>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.argnorm$gdp.per.capita[1])*100)

#for mexico
gdp_data_long_0316.mexnorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.mex") 

gdp_data_long_0316.mexnorm <- gdp_data_long_0316.mexnorm %>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.mexnorm$gdp.per.capita[1])*100)

#binding the above
gdp_data_base100 <- rbind(gdp_data_long_0316.argnorm, 
                          gdp_data_long_0316.branorm, 
                          gdp_data_long_0316.chinorm,
                          gdp_data_long_0316.latnorm,
                          gdp_data_long_0316.mexnorm)

#creating graph
plot.0316.base <- ggplot(gdp_data_base100, aes(x = year, y = gdp.per.capita, color = country)) +
  geom_line() +
  labs(title = "Growth Trends for Selected Countries",
       x = "Year",
       y = "2003 GDP Per Capita = 100",
       color = "Country") +
  scale_color_manual(values = c("lightblue", "green", "firebrick", "purple", "orange"), 
                     name = "", 
                     breaks = c("gdp.arg", "gdp.bra", "gdp.chile", "gdp.lat.avg", "gdp.mex"),
                     labels = c("Argentina", "Brazil", "Chile", "LaTam Avg.", "Mexico")) +
  theme_base() +
  theme(axis.title = element_text(size = 12), plot.title = element_text(size = 15)) +
  scale_x_continuous(breaks = unique(gdp_data_long_0016$year)) +
  theme(axis.text.x = element_text(size = 8), axis.text.y = element_text(size = 9)) +
  theme(legend.position = "bottom", plot.title.position = "panel") +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5), legend.text = element_text(size = 11)) +
  ylim(99, 151)



```

```{r graph 2, echo=FALSE, results='markup', fig.cap='Figure 2'}
plot.0316.base
```

When we observe the growth trends starting with the same normalized base in 2003, one can conclude that the statement that "Brazil took off" is probably not the best definition for what happened in the period. While Brazil does present a better trend than Mexico, it lags behind the Latin American average, Chile, and Argentina.

The two figures above also show that comparative measures accross different countries or even regional averages are not optimal. Our goal should not be to compare Brazil to any one other country, since it is clear that none of the lines above follow Brazil's trend during our pre intervention period, so we cannot draw an informative conclusion on why Brazil has under performed or even if it has under performed at all. Maybe this trend was the best that the Brazilian economy could do in this period. In order to perform a more sound analysis, we must get as close as possible to constructing a precise counterfactual to the Brazilian economy. This is where the synthetic control method comes in, the topic of the final section of this research proposal.

## 4- The Synthetic Control Method

Following @abadie2015comparative, I close this research proposal by describing the mathematical model of the synthetic control method and explain how it provides a preliminary test for or against the validity of the hypothesis described above. 

The intuition for the SCM is quite simple. When our units of analysis are a few aggregate entities (e.g. countries in a yearly panel), a combination of comparison units often does a better job of reproducing the characteristics of the unit of interest than any single comparison unit alone. Therefore, the result of our model is a synthetic control that is selected as the weighted average of all potential comparison units that **best resembles the characteristics of the unit of interest** in the **preintervention** period. 

I will further discuss the assumptions that must hold for us to get as close as possible to causal conclusions from synthetic controls in future assignments. For now, let's dive into the setup of the model by defining our parameters.

### The setup of the SCM

We have a sample of $J + 1$ countries where $j = 1$ is our country of interest (Brazil) and $j = 2,..., J + 1$ are our potential comparison units (the 19 other countries in our sample).

All our units are observed at the same time periods $t = 1,..., T$. There is a positive number of preintervention periods ($T_0$) and postintervention periods ($T_1$) such that $T = T_0 + T_1$. 

$j = 1$ is exposed to the intervention on periods $T_0 + 1,..., T$ and the intervention has no effect on $j = 1$ during periods $1,..., T_0$.

Our synthetic control will be composed of two key parameters: the weights assigned to the units of comparison (denoted as $w$) and the weights assigned to the covariates (also called the predictors of our variable of interest in SCM literature and denoted as $v$). The goal is to construct a synthetic control that resembles, as best as possible, the trend of the variable of interest (e.g. GDP per capita) of our unit of interest during the preintervention period.

The weights assigned to the comparison units are described by a $(J \times 1)$ vector of weights $W$, where:

$W\ =\ (w_2,..., w_{J+1})'$ ($'$ denotes the transpose of the vector)

Such that $0 \le w_j \le 1$ for $j=2,..., J+1$ and $w_2\ +\ ...\ +\ w_{J+1}\ =\ 1$

The weights assigned to our covariates are specifically denoted as $v_m$, where we have $m\ =\ 1,..., k$ covariates in the study and are also normalized to sum to 1.

Let $X_1$ be a $(k \times 1)$ vector containing the values of **preintervention** variables of the **unit of interest** that we aim to match as closely as possible.

And let $X_0$ be a $(k \times J)$ matrix collecting the values of **the same preintervention variables** for the **comparison units**.

Therefore, the difference between preintervention characteristics of the unit of interest and the synthetic control is given by the vector $X_1\ -\ X_0W$. We select the synthetic control $W^*$ that minimizes the size of this difference.

The last parameter we must define addresses our variable of interest (think, again, of GDP per capita). We let $Y_{jt}$ be the variable of interest of unit $j$ at time $t$.

We are now ready to derive our synthetic control.

### Deriving the synthetic control

In order to avoid the dangers of overfitting while still minimizing out-of-sample prediction errors, the first step in the derivation is to emply a cross-validation technique to choose the weights $v_m$.

We divide the pretreatment period into a training period (I will use 1990-2001) and a validation period (I will use 2002-2006). Using the covariates measured in the training period, we select the weights $v_m$ such that the result minimizes the root mean square prediction error of the validation period:

$$
\min(RMSPE)=\min((\frac{1}{T_0}\sum^{T_0}_{t=1}(Y_{1t}-\sum_{j=2}^{J+1}w^{*}_{j}Y_{jt})^{2})^{\frac{1}{2}})
$$

Now, we apply the the $v_m$ weights derived above and choose $W^*$ as the value that solves:

$$
\min(\sum^{k}_{m=1}v_m(X_{1m}-X_{0m}W)^2)
$$

This results in a synthetic control that approximates as best as mathematically possible the preintervention trend of GDP per capita in Brazil. If the resulting synthetic control has a preintervention GDP per capita trend that is similar to Brazil's, we will have succeed in our goal of building a reliable counterfactual to the Brazilian economy. Thus, since our counterfactual is a relibale synthetic version of the Brazilian economy during the preintervention period, but is not exposed to the intervention of interest during the postintervention period, we are able to estimate the effect of the intervention of interest on GDP per capita in Brazil as the difference in GDP per capita levels between Brazil and its synthetic counterpart in the years following the intervention.

In mathematical terms and following the definition of $Y_{jt}$ above, the synthetic control estimator of the effect of the treatment in any post intervention period $t=T_0+1,...T$ is given by the comparison between the variable of interest for the unit of interest and the variable of interest for the synthetic control at that period:

$$
Y_{1t}-\sum^{J+1}_{j=2}w^{*}_{j}Y_{jt}
$$

The derivation above does not mention many of the technical details that corroborate for the validity of the SCM in constructing a reliable counterfactual to our country of interest. I am more than happy to dive deeper into these details in our subsequent submissions if you judge that to be necessary.

## Next Steps (mainly notes for myself)

- Discuss assumptions in the selection of the country pool (geography, population, gdp per capita trend, explain why I needed to drop argentina, venezuela, russia, thailand, indonesia, philippines, malaysia). Discuss assumptions that must hold in order for us to get close to a causal interpretation of the resulting synthetic control to be valid.

- Discuss inference tests: placebo and robustness (tests that can help justify the assumptions, using variables that are available in my dataset).

- As discussed in our meeting, I will define an alternative variable to be used as the variable of interest in the creation of another synthetic control as a sanity check (show trend on both the v and w weights of main result and in the v and w weights derived for this new variable of interest)

## My questions

- My references look a little weird, how can I fix that? (for example, for them to show Abadie et al. (2015) in the text instead of @abadie2015comparative)

- How to optimize the input of references in the bibliography? (I am doing it manually in a references.bib file and I guess that there is probably a better way)

- How can I make my Figure 1 and Figure 2 captions centered? I tried a lot of different things and it did not work.

- How can I get rid of the box around my plots? (the one that is outside of the title and axis)

end of the assignment :)

