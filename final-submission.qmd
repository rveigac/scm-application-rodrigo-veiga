---
title: "Final Submission"
author: "Rodrigo Veiga"

institute: "University of Pennsylvania"
date: last-modified
toc: true

bibliography: References.bib

format: 
  html:
    self-contained: true

editor: source
---

```{r libraries, include=FALSE}
#libraries
library(ggplot2)
library(ggthemes)
library(readr)
library(ggdag)
library(tidyverse)
library(gt)
library(modelsummary)

#other libraries that support my style of coding
library(tidyverse)
library(rio)
#library(tidylog)
library(gapminder)
library(janitor)
library(kableExtra)
```

# Brazil and the New Economic Matrix: An Application of the Synthetic Control Method

## Introduction

In late 2009, The Economist published a cover featuring Rio de Janeiro’s Cristo Redentor with the header “Brazil takes off”^[See https://www.economist.com/leaders/2009/11/12/brazil-takes-off]. Less than four years later, it again published a cover featuring Brazil’s Cristo but this time, it questioned: “Has Brazil blown it?”^[See https://www.economist.com/leaders/2013/09/27/has-brazil-blown-it]. What happened in the meantime? This story, like many others that overlap economic policy and electoral politics, is not so straightforward.

This project proposes that the analysis of these questions must focus on a broader timeline. During most of the first two decades of the 21^st^ century, the Brazilian Workers Party presided over the Federal Executive branch (2003-2016). The period was marked by many social advances and improvements in the standards of living but also by corruption scandals, a major global recession, and a severe domestic economic crisis in the 2014-2016 period.

Amid such a noisy environment, the goal of this project is to analyze the impact of economic policies that came to be known as the New Economic Matrix on the trend of GDP per capita in Brazil. I apply the synthetic control method (SCM) using data from the 1990-2018 period, a sample of 19 control countries, and variables that are known predictors of GDP per capita. The SCM is a statistical technique used for causal inference analysis. Developed in a series of papers by @abadie2003economic, @abadie2010synthetic, and @abadie2015comparative – among others – the central focus of this method is to create a counterfactual scenario where a unit of interest (e.g., a country) did not receive a treatment (e.g., a specific set of policies).

With that in mind, my main research question is: 

**Did the New Economic Matrix, instituted by the Workers Party starting in 2006, positively or negatively impact GDP per capita in Brazil?**

This question builds upon a wide range of existing research on the topic. My goal is to add to the discussion from two papers that have used the same empirical method I will imply, albeit with relevant differences in the research question and methodological setting than mine. @carrasco2014decada apply the synthetic control method (SCM) to quantify the impact of the Workers Party tenure on economic development in Brazil. They apply the start of President Lula's first presidential administration as the event of interest and set 2003 as the intervention year. The authors argue that the Party had a negative impact of about 12% in Brazil's GDP per capita as of 2012. @balassiano2018recessao attempts to quantify the impact that domestic factors had on the severity of the Brazilian recession of 2014-2016. The author found evidence that the substantial deterioration of the Brazilian economy was more a result of internal than external factors.

While the studies mentioned above are informative, their results are sub-optimal because their synthetic controls fall short of representing credible counterfactuals to the trend of GDP per capita in Brazil. State-of-the-art literature on the SCM (cited below) asserts that you must have an event that characterizes a clear, traceable break separating before and after scenarios. I argue that the intervention year (2003) in @carrasco2014decada is not ideal because there are no major shifts in economic policy-making during the first three years of Lula's first term as President. There are also no major shifts, breaks or shocks in the choice of intervention year (2013) in @balassiano2018recessao.

The 2003-2005 period is marked by continuity in terms of economic policy-making. Similarly, 2013 is indeed the year before the beginning of the recession, but it is not marked by any specific event or structural changes in economic policy. Therefore, while @carrasco2014decada attempt to create a synthetic Brazil without the Workers Party and @balassiano2018recessao, a synthetic Brazil free of the negative domestic shocks of 2014-2016, their conclusions are weakened by sub-optimal pre-intervention fits. I argue at least that part of this noise is explained by the fact that they are not asking the question that the SCM is best equipped to answer: What is the impact of shifts in policy-making?

Extensive research on economic policy in Brazil presents a clear consensus and points us to the most appropriate setting for the application of synthetic controls. Several different authors employing a myriad of methods [@abreu2014ordem; @barbosa2014desaceleraccao; @borges2016bad; @pessoa2017debate] affirm that a major shift in economic policy (from macro, micro, monetary, fiscal, and public policy perspectives) happened in early 2006, when Guido Mantega, former President of the National Bank of Economic and Social Development (BNDES), was appointed as the new Finance Minister by the presidential administration.

As several authors have pointed out, Mantega’s rise to the Ministry is a well-defined event that marks the ideological and technical shift in economic policy from a liberal to an interventionist perspective [@barbosa2014desaceleraccao; @pessoa2017debate; @resende2018economia]. The media, the government, and academia eventually labeled this shift as the New Economic Matrix (NEM). The NEM can be broadly defined as the increase in the state’s intervention in the functioning and shape of markets [@pessoa2017debate]. The NEM takes the form of several macro and microeconomic policies adopted over the course of the 2006-2018 period that were not present before Mantega assumed the role of Finance Minister, a non-exhaustive list of which follows.

**Some of the core NEM policies were:** change from a floating exchange rate regime to a strongly managed one**;** recurrent adoption of artificial measures to achieve the primary surplus target, reducing fiscal policy transparency, along with a progressive reduction of the primary surplus**;** reduction, without the fundamentals allowing, of the real interest rate and, therefore, greater tolerance towards inflation^[Note that the Brazilian Central Bank only obtained full autonomy and independence from the Federal Executive in 2021. See https://www.reuters.com/article/us-brazil-centralbank/brazil-enacts-law-guaranteeing-central-bank-autonomy-idUKKBN2AP02D/]**;** widespread price controls and microeconomic interventionism, mainly in public utilities and the oil sectors, as an alternative mechanism to contain inflation**;** weakening and reduction of the role of regulatory agencies**;** expansion of subsidized credit, especially through BNDES, to stimulate investment, with strong discretion regarding the favored entities**;** reduction of openness to international trade**;** expansion of discretionary policies, such as tax breaks for specific sectors or selected goods, at the expense of horizontal policies that treat most sectors equally**;** increased public intervention and the role of Petrobras in the oil sector**;** intervention in the electricity sector to anticipate concession renewals**;** use of public banks to reduce the banking spread**;** indiscriminate use of national content requirements without concern for the repercussions of these measures on production chains, price levels, and the total factor productivity of the country [@pessoa2017debate; @holland2017matriz; @roriz2016efeitos]^[See @roriz2016efeitos in @bacha2016crise.].

It is important to understand understand what led to this leadership change in the Finance Ministry and a shift in the overall policy-making strategy. In mid-2005, the political tide in Brazil changed, ultimately ending what some have called a fifteen-year trend in the choice of the economic policy playbook [@resende2018economia]. Such change started with the Mensalão crisis, one of the major corruption scandals that tainted Brazilian politics in the early 2000s. The Federal Executive administration was, in short, illegally buying votes in Congress in favor of their bills. Many high figures within the Workers Party had to step away from politics, and some were prosecuted. More importantly, Lula’s political calculations had changed. With the onset of a major scandal, incentives pushed the administration away from setting up long-term policies to using the state’s political and financial apparatus to guarantee the President’s chances of reelection. This new prioritization was clearly antagonistic to the policies Antonio Palocci, then Finance Minister, was advocating. He was, for example, pushing for a redefinition of budgetary rules with the objective of controlling the rate of increase of governmental expenditure, which had been increasing twice as fast as GDP since the 1990s [@werneck2014alternancia]^[See @werneck2014alternancia in @bacha2016crise.]. In early 2006, Palocci was accused of abuse of power and forced to step down. As mentioned above, Lula then replaced him with Guido Mantega.

Therefore, we must keep in mind that the uncovering of a major corruption scandal and the possible increase in the level of perception of corruption in Brazil might confound the treatment/intervention timing and the impact of the New Economic Matrix on the Brazilian economy. This topic is further discussed below.

With that said, the change in the Finance Ministry clearly marks a new era of economic policy-making strategies, which would last for the remainder of Lula’s tenure (2006-2010), the entirety of his successor’s, Dilma Rousseff, time as President (2010-2016), and the two years (2016-2018) during which Brazil was ruled by an Interim Presidencial cabinet. Dilma was impeached in 2016 under accusations of creative accounting and, as it was argued, fraudulent measures that had been masking the true state of the government’s financial health leading up to her bid for reelection in 2014, the so-called *Pedaladas Fiscais* (Fiscal Pedaling) [@bacha2016crise].

The analysis presented below aims to fill the gap in knowledge related to the quantification of the impact of New Economic Matrix policies on GDP per capita in Brazil through the lenses of an original setup and application of the synthetic control method.

## Theory and Hypothesis

My main hypothesis is that we will observe a negative impact of the NEM in Brazil's GDP per capita trend. This hypothesis is informed by two main arguments.

First, it has been shown that the NEM had negative effects in the Brazilian economy. @borges2017debate, for example, uses three different methodological approaches to argue that – both domestic and external – factors exogenous to the Brazilian economy are responsible for approximately 50% of the economic downturn in the 2012 - 2016 period. While he demonstrates support for some policies packaged within the NEM and argues that the deceleration in potential growth can be tied to several factors that are exogenous to economic policy, the author accepts that most of the remaining 50% are caused by domestic economic policy mistakes of the NEM^[Not **all** of the remaining 50%, since the author leaves room for measurement errors there]. Therefore, I hypothesize that my results are going to be in line with previous literature.

Second, while the results in @balassiano2018recessao are not particularly trustworthy, the author does find that Brazil underperformed with respect to the counterfactual in that paper. As mentioned above, I argue that mapping the event that marked the dawn of a new era in economic policy-making in Brazil and making it the focus of my empirical application will pay off in terms of providing more robust and trustworthy results for the synthetic control. Therefore, @balassiano2018recessao indicates that there was a force causing a negative impact in GDP per capita in Brazil and this project attempts to find out whether the New Economic Matrix was such force.

## Research Design

### Data and Sample

The unit of analysis will be a country-year panel. I collected data from the World Bank’s World Development Indicators (WDI) dataset. While the World Bank produces a lot of the data points present in my final dataset, the OECD, IMF, UN, and ILO are the primary sources for some of the variables present in the WDI that are part of my model. Additionally, I collected additional data for Terms of Trade directly from the OECD’s National Accounts at a Glance dataset and merged it with my WDI dataset. My raw dataset is composed of 35 countries and 72 variables over the 1970-2022 period. After extensive research and analysis, I have decided that my synthetic control model will be based on a sample of 20 countries and 8 variables over the 1990-2018 period. Details are provided below.

**Country of interest:** Brazil.

**Country pool/comparison units** (that will be fed into the model to create the synthetic control): Bolivia, Bulgaria, Chile, China, Colombia, Costa Rica, Ecuador, Egypt, India, Iran, Mexico, Pakistan, Paraguay, Peru, Poland, South Africa, Türkiye, Ukraine, and Uruguay.

**Variable of interest:** GDP per capita, PPP (constant 2017 international $).

**Covariates:** Agriculture, forestry, and fishing, value added (% of GDP); GDP per capita, PPP (constant 2017 international $); Gross capital formation (% of GDP); Industry (including construction), value added (% of GDP); Inflation, consumer prices (annual %); Net barter terms of trade index (2015 = 100); Trade Openness (% of GDP) (defined as Exports of goods and services (% of GDP) + Imports of goods and services (% of GDP), following @abadie2015comparative and the concept of additive indexes we learned in class); and Unemployment, total (% of total labor force) (national estimate).

The covariates above will be used to match the pre-intervention GDP per capita trend of the synthetic counterfactual with that of Brazil. 

**Pre-intervention period**: 1990 - 2005

There is one minor limitation that the reader must the aware of. The results derived below do not take the 1995 values of the variables for any of the comparison units and Brazil into consideration when performing the calculations. This year is full of idiosyncratic and volatile shocks that had short-term impacts in some of our units^[For example, the Mexican Peso crisis. See https://www.federalreserve.gov/pubs/bulletin/1996/396lead.pdf]. Note, however, that this does not undermine the validity of the analysis. This is simply an attempt to allow for a larger numbar of pre-intervention periods than in @carrasco2014decada, while still constructing results that are not noised by short-term idiosyncratic shocks. Furthermore, as highlighted by @abadie2015comparative [p. 497], the mathematical model of synthetic control derivations does not require the sample periods to be equidistant in time.

**Post-intervention period**: 2006 (intervention year) - 2018 (the last year before Jair Bolsonaro, the winner of the 2018 Presidential Elections, took over as President).

**Intervention of interest:** The change in Finance Minister in early 2006. Antônio Palocci was replaced by Guido Mantega, setting off the policy changes that encompass what is defined as the New Economic Matrix.

### Preliminary Visualization

Here, I present two preliminary figures and two tables. 

The figures trace Brazilian GDP per capita in comparison with selected countries. The goal of this preliminary visualization exercise is twofold. One, to investigate whether Brazil actually took off in the early 2000s, as the 2009 cover for The Economist affirmed. Two, to make the case for why the synthetic control method is the best empirical tool available to help shed light upon the research question.

```{r graph 1 prep, include=FALSE}
####Loading and cleaning original dataset####

#loading libraries
library(tidyr)
library(foreign)
library(Synth) 
library(xtable)
library(tidyverse)
library(rio)
#library(tidylog)
library(readxl)
library(ggthemes)
library(gridExtra)

setwd("/Users/rodrigo/Documents/GitHub/scm-application-rodrigo-veiga")

data.raw <- read.csv("data/Data.raw.csv")

#datasets to be merged with the cleaned version of the one above:
data.ttrade <- read.csv("data/Indonesia terms of trade.csv")


#the plan is to clean the dataset and make it look like the one named "d" in the rep.r file under the CODING EXAMPLES folder
#I will use data.raw as my starting point. once the new dataset based on data.raw looks similar to "d"'s format I will add the information on data.deficit as a new column

data.clean <- data.raw

#--
#1. Renaming country column using colnames()
colnames(data.clean)[colnames(data.clean) == "Country.Code"] <- "country"

#--
#2. Renaming country name column using colnames()
colnames(data.clean)[colnames(data.clean) == "Country.Name"] <- "index"

#--
#3.Changing entries of the new index column to numbers (based on "d" format)
data.clean$index[data.clean$index == "Argentina"] <- 1
data.clean$index[data.clean$index == "Australia"] <- 2
data.clean$index[data.clean$index == "Bolivia"] <- 3
data.clean$index[data.clean$index == "Brazil"] <- 4
data.clean$index[data.clean$index == "Bulgaria"] <- 5
data.clean$index[data.clean$index == "Chile"] <- 6
data.clean$index[data.clean$index == "China"] <- 7
data.clean$index[data.clean$index == "Colombia"] <- 8
data.clean$index[data.clean$index == "Costa Rica"] <- 9
data.clean$index[data.clean$index == "Ecuador"] <- 10
data.clean$index[data.clean$index == "Egypt, Arab Rep."] <- 11
data.clean$index[data.clean$index == "Hungary"] <- 12
data.clean$index[data.clean$index == "India"] <- 13
data.clean$index[data.clean$index == "Indonesia"] <- 14
data.clean$index[data.clean$index == "Iran, Islamic Rep."] <- 15
data.clean$index[data.clean$index == "Lithuania"] <- 16
data.clean$index[data.clean$index == "Malaysia"] <- 17
data.clean$index[data.clean$index == "Mexico"] <- 18
data.clean$index[data.clean$index == "Pakistan"] <- 19
data.clean$index[data.clean$index == "Paraguay"] <- 20
data.clean$index[data.clean$index == "Peru"] <- 21
data.clean$index[data.clean$index == "Philippines"] <- 22
data.clean$index[data.clean$index == "Poland"] <- 23
data.clean$index[data.clean$index == "Romania"] <- 24
data.clean$index[data.clean$index == "Russian Federation"] <- 25
data.clean$index[data.clean$index == "South Africa"] <- 26
data.clean$index[data.clean$index == "Thailand"] <- 27
data.clean$index[data.clean$index == "Turkiye"] <- 28
data.clean$index[data.clean$index == "Ukraine"] <- 29
data.clean$index[data.clean$index == "United States"] <- 30
data.clean$index[data.clean$index == "Uruguay"] <- 31
data.clean$index[data.clean$index == "Venezuela, RB"] <- 32

#--
#4. now I need to reshape my dataset. It is originally in the wide format (where each year has its 
#own column) and I want it to be on a long format, where I have a single column for years and 
#a separate column for each variable type.

#4.1 let's first rename our year columns
# Renaming year column using colnames() and sub()
colnames(data.clean) <- sub("^X(\\d{4})\\.\\.YR\\1\\.$", "\\1", colnames(data.clean))

#4.2 deleting the series.code column
data.clean.nocode <- subset(data.clean, select = -Series.Code)

#4.3 transforming each column year into a column that contains the years
data.clean.long <- gather(data.clean.nocode, key = "Year", value = "Value", "1970":"2022")

#4.4 adjusting dataset above to make "" entries in country column to be NA entries
data.clean.long$country <- replace(data.clean.long$country, data.clean.long$country == "", NA)

#4.5 adjusting dataset above to remove rows that have NA in the country column
data.clean.long2 <- data.clean.long[complete.cases(data.clean.long$country), ]

#4.6 transforming the column series.name into several columns, each representing one variable
data.clean.finalish <- spread(data.clean.long2,Series.Name,Value) #now this dataset has the same format as the one used by abadie (dataset "d")

#--

#5. Making my dataset have NAs in empty entries

data.clean.finalish[data.clean.finalish == ".."] <- NA

#--

#6. Subsetting variables to be used in this version

data.v6.vars <- data.clean.finalish[, c("index", 
                                            "country", 
                                            "Year", 
                                            "Agriculture, forestry, and fishing, value added (% of GDP)", 
                                            "Central government debt, total (% of GDP)", 
                                            "Exports of goods and services (constant 2015 US$)",
                                            "Exports of goods and services (% of GDP)", #will use exports and imports as % of gdp summed in a variable called trade openness
                                            "GDP per capita, PPP (constant 2017 international $)", 
                                            "Gross capital formation (% of GDP)", 
                                            "Imports of goods and services (constant 2015 US$)",
                                            "Imports of goods and services (% of GDP)", #will use exports and imports as % of gdp summed in a variable called trade openness
                                            "Industry (including construction), value added (% of GDP)", 
                                            "Inflation, consumer prices (annual %)", 
                                            "Net barter terms of trade index (2015 = 100)", 
                                            "Official exchange rate (LCU per US$, period average)", 
                                            "Unemployment, total (% of total labor force) (national estimate)")]

#6.1 renaming columns

data.v6.vars <- data.v6.vars %>%
  rename(
    year = Year,
    agva = "Agriculture, forestry, and fishing, value added (% of GDP)",
    debt = "Central government debt, total (% of GDP)",
    exportspct = "Exports of goods and services (% of GDP)",
    gdpc = "GDP per capita, PPP (constant 2017 international $)",
    gcf = "Gross capital formation (% of GDP)",
    importspct = "Imports of goods and services (% of GDP)",
    indva = "Industry (including construction), value added (% of GDP)",
    infrate = "Inflation, consumer prices (annual %)",
    termstrade = "Net barter terms of trade index (2015 = 100)",
    unemp = "Unemployment, total (% of total labor force) (national estimate)"
  ) 

#6.2 making stuff numeric
conv_cols <- c("index",
               "year",
               "agva",
               "debt",
               "exportspct",
               "gdpc",
               "gcf",
               "importspct",
               "indva",
               "infrate",
               "termstrade",
               "unemp"
               )

data.v6.vars <- data.v6.vars %>% 
  mutate_at(conv_cols, as.numeric)

#6.3 Following SCM best practices and Abadie (2015), here I create the variable trade openness
#Trade Openness: Exports plus Imports as percentage of GDP
data.v6.vars <- data.v6.vars %>% 
  mutate(tradeop = exportspct + importspct)

#6.4 Following SCM best practices and Abadie (2015), here I am rounding GDP per capita
data.v6.vars <- data.v6.vars %>% 
  mutate(gdpc = round(gdpc))

#--

#7 Merging datasets

#7.1 Adding updated Indonesia terms of trade info
data.ttrade.merge <- data.ttrade %>% 
  select(LOCATION, TIME, Value)

data.v6.vars.step7 <- data.v6.vars %>%
  mutate(termstrade = ifelse(country == "IDN" & year >= 1993 & year <= 2022,
                             data.ttrade.merge$Value[match(year, data.ttrade.merge$TIME)],
                             termstrade))
#now the dataset has incorporated all the updated data and is ready for analysis
data.v6 <- data.v6.vars.step7

#--

#8. Getting data ready for graphs

#subsetting only variable I will use for graphs here (gdpcv2)
data.intro.graphs <- data.v6 %>% 
  select(index, country, year, gdpc)

#subsetting into Brazil, Chile, Mexico, Argentina, and LaTam

#Brazil
data.brazil <- data.intro.graphs %>% 
  filter(country == "BRA")

#Chile
data.chile <- data.intro.graphs %>% 
  filter(country == "CHL")

#Mexico
data.mex <- data.intro.graphs %>% 
  filter(country == "MEX")

#Argentina
data.arg <- data.intro.graphs %>% 
  filter(country == "ARG")

##LaTam##
#selecting countries
data.latam <- data.intro.graphs %>%
  filter(country %in% c("ARG",
                        "BOL", #took brazil out
                        "CHL", 
                        "COL", 
                        "CRI", 
                        "ECU", 
                        "MEX", 
                        "PRY", 
                        "PER",
                        "URY")) #original dataset has no information for venezuela
unique(data.latam$country)

#creating average
data.lat.avg <- aggregate(gdpc ~ year, data = data.latam, FUN = mean, na.rm = TRUE) #first year w/o na is 1990

#subsetting others to start from 1990
data.brazil.90 <- data.brazil %>% 
  filter(year >= 1990)

data.chile.90 <- data.chile %>% 
  filter(year >= 1990)

data.mex.90 <- data.mex %>% 
  filter(year >= 1990)

data.arg.90 <- data.arg %>% 
  filter(year >= 1990)

#creating one dataset out of that info
final.data.intro.graphs <- data.lat.avg %>% 
  rename(gdp.lat.avg = gdpc)

#subsetting country-specific datasets
br.tobind <- data.brazil.90 %>% 
  select(gdpc) %>% 
  rename(gdp.bra = gdpc)

chile.tobind <- data.chile.90 %>% 
  select(gdpc) %>% 
  rename(gdp.chile = gdpc)

arg.tobind <- data.arg.90 %>% 
  select(gdpc) %>% 
  rename(gdp.arg = gdpc)

mex.tobind <- data.mex.90 %>% 
  select(gdpc) %>% 
  rename(gdp.mex = gdpc)

#binding them into dataset I will use for the graphs
this.for.graph <- cbind(final.data.intro.graphs, br.tobind, chile.tobind, arg.tobind, mex.tobind)

#pivoting data in long format
gdp_data_long <- this.for.graph %>%
  pivot_longer(cols = starts_with("gdp"), names_to = "country", values_to = "gdp.per.capita")

#--

#9. PLOT OF GDP PER CAPITA OVER TIME 2000-2018 (Figure 1)
gdp_data_long_0016 <- gdp_data_long %>% 
  filter(year >= 2000 & year <= 2018)

plot.0018.gdp <- ggplot(gdp_data_long_0016, aes(x = year, y = gdp.per.capita, color = country)) +
  geom_line() +
  labs(
       x = "Year",
       y = "GDP per capita, PPP (2017 int. $)",
       title = "GDP Per Capita for Selected Countries",
       color = "Country") +
  scale_color_manual(values = c("lightblue", "green", "firebrick", "purple", "orange"), 
                     name = "", 
                     breaks = c("gdp.arg", "gdp.bra", "gdp.chile", "gdp.lat.avg", "gdp.mex"),
                     labels = c("Argentina", "Brazil", "Chile", "LaTam Avg.", "Mexico")) +
  theme_base() +
  theme(axis.title = element_text(size = 12), plot.title = element_text(size = 15)) +
  scale_x_continuous(breaks = c(2000,2002,2004,2006,2008,2010,2012,2014,2016,2018)) +
  scale_y_continuous(breaks = c(12000,16000,20000,24000)) +
  theme(axis.text.x = element_text(size = 10), axis.text.y = element_text(size = 10)) +
  theme(legend.position = "bottom", plot.title.position = "panel") +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5), legend.text = element_text(size = 11))

plot.0018.gdp

#-----

#10. GROWTH TRENDS FOR SELECTED COUNTRIES (base 100 graph) (FIGURE 2)

#filtering years in the graph
gdp_data_long_0316 <- gdp_data_long %>% 
  filter(year >= 2003 & year <= 2018)

#normalizing base

#for latam avg
gdp_data_long_0316.latnorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.lat.avg") 

gdp_data_long_0316.latnorm <- gdp_data_long_0316.latnorm %>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.latnorm$gdp.per.capita[1])*100)

#for brazil
gdp_data_long_0316.branorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.bra") 

gdp_data_long_0316.branorm <- gdp_data_long_0316.branorm %>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.branorm$gdp.per.capita[1])*100)

#for chile
gdp_data_long_0316.chinorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.chile") 

gdp_data_long_0316.chinorm <- gdp_data_long_0316.chinorm%>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.chinorm$gdp.per.capita[1])*100)

#for argentina
gdp_data_long_0316.argnorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.arg") 

gdp_data_long_0316.argnorm <- gdp_data_long_0316.argnorm %>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.argnorm$gdp.per.capita[1])*100)

#for mexico
gdp_data_long_0316.mexnorm <- gdp_data_long_0316 %>% 
  filter(country == "gdp.mex") 

gdp_data_long_0316.mexnorm <- gdp_data_long_0316.mexnorm %>% 
  mutate(gdp.per.capita = (gdp.per.capita/gdp_data_long_0316.mexnorm$gdp.per.capita[1])*100)

#binding the above
gdp_data_base100 <- rbind(gdp_data_long_0316.argnorm,
                          gdp_data_long_0316.branorm,
                          gdp_data_long_0316.chinorm,
                          gdp_data_long_0316.latnorm) #taking mexico out    

#creating graph
plot.0316.base <- ggplot(gdp_data_base100, aes(x = year, y = gdp.per.capita, color = country)) +
  geom_line() +
  labs(
       x = "Year",
       y = "2003 GDP Per Capita = 100",
       title = "GDP per Capita Growth Trends for Selected Countries",
       color = "Country") +
  scale_color_manual(values = c("lightblue", "firebrick", "green", "purple"), #
                     name = "", 
                     breaks = c("gdp.arg", "gdp.chile", "gdp.bra", "gdp.lat.avg"), #
                     labels = c("Argentina", "Chile", "Brazil","LaTam Avg.")) + #    
  theme_base() +
  theme(axis.title = element_text(size = 12), plot.title = element_text(size = 15)) +
  scale_x_continuous(breaks = c(2003,2006,2009,2012,2015,2018)) +
  theme(axis.text.x = element_text(size = 10), axis.text.y = element_text(size = 10)) +
  theme(legend.position = "bottom", plot.title.position = "panel") +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5), legend.text = element_text(size = 11)) +
  ylim(99, 151)

plot.0316.base

```

```{r graph 1, echo=FALSE, results='markup', fig.cap='Figure 1. Notes: Latin American average is defined as the sum of GDP per capita values for Argentina, Bolivia, Chile, Colombia, Costa Rica, Ecuador, Mexico, Paraguay, Peru, and Uruguay, divided by the count of countries (10).'}
plot.0018.gdp
```

In Figure 1, we see that Brazil starts the 2000s with GDP per capita levels significantly below that of Argentina, Chile, and Mexico. Brazil spends the following 11 years relatively in line with the Latin American average. It is never able to catch up with its selected peers (although it does get closer to Mexico). This is informative, but not a good base for comparison. 

We can try to normalize this figure and focus on the 2003-2016 timeline during which the Workers Party uninterruptedly held the Presidency in Brazil. Figure 2 plots the PPP GDP per capita measured in 2017 international dollars normalized to 2003 levels. One can see that the Brazilian GDP per capita growth path had a steep decline after 2013, culminating in one of the worst economic crises of the country’s history, with a 4.4% decline in GDP per capita in 2015.

```{r graph 2, echo=FALSE, results='markup', fig.cap="Figure 2. Notes: Each country's yearly GDP per capita value is divided by its 2003 value. The Latin American average is defined in Figure 1 and normalized in the same manner described above."}
plot.0316.base
```

When taking both figures and the historic trend of Brazilian GDP per capita^[See the following for an expanded timeline of Figure 1: https://data.worldbank.org/indicator/NY.GDP.PCAP.PP.KD?end=2022&locations=BR-AR-CL-MX&start=1990] into consideration, one is led to conlude that the take-off affirmation is, at best, relative. Compared to the Brazilian trends of the 1980s and 1990s, the 2003-2013 period can indeed characterize as a take-off. The growth trajectory in this period is much steadier and positive than in previous decades. Compared to its Latin American peers, however, the best definition would perhaps be an attempt to catch-up. Figure 2 shows that, even though the growth trend is more promising than that of the late 20^th^ century, Brazil still has the slowest growth trajectory when compared to Argentina, Chile, and the Latin American average.

The table below summarizes the 2000-2005 country average and the country growth rate average for one of the key variables in this project: GDP per capita. It shows the period average for each of the 19 control countries and for Brazil.


```{r table 1, echo=FALSE, results='markup', fig.cap="<span style='font-size: smaller; color: gray;'>Table 1. Notes: GDP per capita is averaged for the 2000-2005 period and in PPP 2017 international $. The growth rate average is the average of the yearly GDP per capita growth rates during the 2000-2005 period."}
#10. Here I will subset the main dataset to construct Table 1 using the kableExtra package

#10.1 Subsetting countries I will use for this table and the final analysis of my analysis 
#This version will use the country list described in step 0
#List: BOL, BRA, BGR, CHL, CHN, COL, CRI, ECU, EGY, IND, IRN, MEX, PAK, PRY, PER, POL, ZAF, TUR, UKR, URY

data.v6 <- data.v6[data.v6$country %in% c("BOL", 
                                          "BRA", 
                                          "BGR", 
                                          "CHL", 
                                          "CHN", 
                                          "COL", 
                                          "CRI", 
                                          "ECU", 
                                          "EGY", 
                                          "IND", 
                                          "IRN",
                                          "MEX",
                                          "PAK", 
                                          "PRY",
                                          "PER",
                                          "POL",
                                          "ZAF",
                                          "TUR",
                                          "UKR",
                                          "URY"), ]

#checking
#length(unique(data.v6$country))
#unique(data.v6$country)

#arranging rows in alphabetical order of country names
data.v6 <- data.v6 %>% arrange(country)
#unique(data.v6$country)

#10.2 Subsetting periods and variable of interest for building table 1
t1_subset <- data.v6 %>% 
  select(country, gdpc, year) %>% 
  filter(year >= 2000 & year <= 2005)

#10.3 creating GDP per capita averages
t1_avgs <- t1_subset %>% 
  group_by(country) %>% 
  summarise(gdpc = mean(gdpc))

t1_avgs$gdpc <- round(t1_avgs$gdpc,1)

#10.4 Creating GDP per capita growth averages
t1_subset_long <- t1_subset %>% 
  pivot_wider(names_from = year,
              values_from = gdpc)

t1_subset_long <- t1_subset_long %>% 
  rename(yr00 = '2000',
         yr01 = '2001',
         yr02 = '2002',
         yr03 = '2003',
         yr04 = '2004',
         yr05 = '2005')

t1_subset_long <- t1_subset_long %>%
  mutate(grate01 = ((yr01-yr00)/yr00)*100,
         grate02 = ((yr02-yr01)/yr01)*100,
         grate03 = ((yr03-yr02)/yr02)*100,
         grate04 = ((yr04-yr03)/yr03)*100,
         grate05 = ((yr05-yr04)/yr04)*100)

t1_subset_long <- t1_subset_long %>%
  rowwise() %>% 
  mutate(avg.grate = mean(c(grate01, grate02, grate03, grate04, grate05)))

#10.5 Creating df to be used to create table 1
t1_subset_long_totable <- t1_subset_long %>% 
  select(avg.grate)

t1_totable <- cbind(t1_avgs, t1_subset_long_totable)

#arranging order of rows according to gdp per capita, as suggested
t1_totable <- t1_totable %>%
  arrange(desc(gdpc))

#10.6 Creating table 
t1 <- t1_totable %>%
  select(country, gdpc, avg.grate) %>%
  kbl(caption="GDP per Capita Averages and Growth Averages",
      position = "top", #trying to put figure caption on top, but it did not work. Sorry about that
      format= "html", #we can change this to "latex" and delete "Table 1" to title (latex automatically includes table count)      
      col.names = c("Country","GDP per Capita", "Growth Rate Avg."),
      align = c("l", "r", "r"), #if align = NULL, numeric columns are right-aligned, and other columns are left-aligned
      longtable = T,
      tabular = "longtable",
      digits = 3,
      booktabs = T) %>% 
  kable_classic(full_width = F, html_font = "helvetica")
t1
```

The table and the two figures above indicate that comparative measures across different countries or even regional averages are not optimal. Our goal should not be to compare Brazil to any one other country, since it is clear that none of the lines above follow Brazil's trend during our pre-intervention period. Therefore, we cannot draw an informative conclusion on why Brazil has under performed or even if it has under performed at all. Maybe this trend was the best that the Brazilian economy could do in this period. In order to perform a more sound analysis, we must get as close as possible to constructing a precise counterfactual to the Brazilian economy where the only difference is that such counterfactual was not exposed to the NEM. This is where the synthetic control method comes in, the topic of the remaining sections of the Research Design chapter.

Finally, let's quickly visualize the summary statistics of the covariates for the sample in comparison to Brazil. The table below shows, for the last pre-intervention period, the mean, max, min, and standard deviation values for all countries in the sample (including Brazil), as well as the values of the same variables for Brazil in this same year.

```{r table 2, echo=FALSE, results='markup', fig.cap="<span style='font-size: smaller; color: gray;'>Table 2. Notes: The first four rows show the results of the 2005 summary statistics for the entirety of the country sample. The fifth row shows the 2005 value of each variable for Brazil."}
#11.1 First, let's subset out main df to only show 2005 values and the columns we will use to create the table
t2.editing <- data.v6 %>% 
  filter(year == 2005) %>% 
  select(country, agva, gdpc, gcf, indva, infrate, termstrade,tradeop, unemp)

#11.2 Now let's create the summary statistics for each variable that will be in the df we will use to create the table
#for agva
agva.summ <- summary(t2.editing$agva)
agva.sd <- sd(t2.editing$agva)

#for gdpc
gdpc.summ <- summary(t2.editing$gdpc)
gdpc.sd <- sd(t2.editing$gdpc)

#for gcf
gcf.summ <- summary(t2.editing$gcf)
gcf.sd <- sd(t2.editing$gcf)

#for indva
indva.summ <- summary(t2.editing$indva)
indva.sd <- sd(t2.editing$indva)

#for infrate
infrate.summ <- summary(t2.editing$infrate)
infrate.sd <- sd(t2.editing$infrate)

#for termstrade
termstrade.summ <- summary(t2.editing$termstrade)
termstrade.sd <- sd(t2.editing$termstrade)

#for tradeop
tradeop.summ <- summary(t2.editing$tradeop)
tradeop.sd <- sd(t2.editing$tradeop)

#for unemp
unemp.summ <- summary(t2.editing$unemp)
unemp.sd <- sd(t2.editing$unemp)

#11.3 now creating the table df
t2_totable <- data.frame(summ = NA, 
                         agva = NA, 
                         gdpc = NA, 
                         gcf = NA, 
                         indva = NA, 
                         infrate = NA, 
                         termstrade = NA, 
                         tradeop = NA, 
                         unemp = NA)

#populating table df
t2_totable[1, ] <- c("Mean", 
                     agva.summ[4], 
                     gdpc.summ[4],
                     gcf.summ[4],
                     indva.summ[4],
                     infrate.summ[4],
                     termstrade.summ[4],
                     tradeop.summ[4],
                     unemp.summ[4])

t2_totable[2, ] <- c("Max.", 
                     agva.summ[6], 
                     gdpc.summ[6],
                     gcf.summ[6],
                     indva.summ[6],
                     infrate.summ[6],
                     termstrade.summ[6],
                     tradeop.summ[6],
                     unemp.summ[6])

t2_totable[3, ] <- c("Min.", 
                     agva.summ[1], 
                     gdpc.summ[1],
                     gcf.summ[1],
                     indva.summ[1],
                     infrate.summ[1],
                     termstrade.summ[1],
                     tradeop.summ[1],
                     unemp.summ[1])

t2_totable[4, ] <- c("SD", 
                     agva.sd, 
                     gdpc.sd,
                     gcf.sd,
                     indva.sd,
                     infrate.sd,
                     termstrade.sd,
                     tradeop.sd,
                     unemp.sd)

t2_totable[5, ] <- t2.editing[3,]

t2_totable$agva <- as.numeric(t2_totable$agva)
t2_totable$gdpc <- as.numeric(t2_totable$gdpc)
t2_totable$gcf <- as.numeric(t2_totable$gcf)
t2_totable$indva <- as.numeric(t2_totable$indva)
t2_totable$infrate <- as.numeric(t2_totable$infrate)
t2_totable$termstrade <- as.numeric(t2_totable$termstrade)
t2_totable$tradeop <- as.numeric(t2_totable$tradeop)
t2_totable$unemp <- as.numeric(t2_totable$unemp)

#11.4 now let's create the table
t2 <- t2_totable %>%
  kbl(caption="Summary Statistics for 2005",
      format= "html", #we can change this to "latex" and delete "Table 1" to title (latex automatically includes table count)      
      col.names = c("","Agriculture v.a.", "GDP/capita", "GCF", "Industry v.a.", "Inflation", "Terms of Trade", "Trade Op.", "Unemployment"),
      align = c("l", "r", "r", "r", "r", "r", "r", "r", "r"), #if align = NULL, numeric columns are right-aligned, and other columns are left-aligned
      longtable = T,
      tabular = "longtable",
      digits = 2,
      booktabs = T) %>% 
  kable_classic(full_width = F, html_font = "helvetica")
t2
```

### The Setup for the SCM

Following @abadie2015comparative, I now describe the mathematical model of the synthetic control method. This shows how the SCM provides a test for or against the validity of the hypothesis described above. Furthermore, it also clarifies how the covariates of choice map onto the theoretical concepts that underpin the hypothesis.

The intuition for the SCM is quite simple. When our units of analysis are a few aggregate entities (e.g. countries in a yearly panel), a combination of comparison units often does a better job of reproducing the characteristics of the unit of interest than any single comparison unit alone. Therefore, the result of our model is a synthetic control that is selected as the weighted average of all potential comparison units that **best resembles the characteristics of the unit of interest** in the **preintervention** period. 

Let's dive into the setup of the model by defining our parameters.

We have a sample of $J + 1$ countries where $j = 1$ is our country of interest (Brazil) and $j = 2,..., J + 1$ are our potential comparison units (the 19 other countries in our sample).

All our units are observed at the same time periods $t = 1,..., T$. There is a positive number of preintervention periods ($T_0$) and postintervention periods ($T_1$) such that $T = T_0 + T_1$. 

$j = 1$ is exposed to the intervention on periods $T_0 + 1,..., T$ and the intervention has no effect on $j = 1$ during periods $1,..., T_0$.

Our synthetic control will be composed of two key parameters: the weights assigned to the units of comparison (denoted as $w$) and the weights assigned to the covariates (also called the predictors of our variable of interest in SCM literature and denoted as $v$). The goal is to construct a synthetic control that resembles, as best as possible, the trend of the variable of interest (GDP per capita) of our unit of interest during the pre-intervention period.

The weights assigned to the comparison units are described by a $(J \times 1)$ vector of weights $W$, where:

$W\ =\ (w_2,..., w_{J+1})'$^[' denotes the transpose of the vector.]

Such that $0 \le w_j \le 1$ for $j=2,..., J+1$ and $w_2\ +\ ...\ +\ w_{J+1}\ =\ 1$

The weights assigned to our covariates are specifically denoted as $v_m$, where we have $m\ =\ 1,..., k$ covariates in the study and are also normalized to sum to 1. Recall that the model has 8 covariates, so $v_m=(v_1,..., v_k)^{'}$ for $k=1,..., 8$. Additionally, each $v_k$ must be such that $0 \leq v_k \leq 1$ .

Let $X_1$ be a $(k \times 1)$ vector containing the values of **preintervention** variables of the **unit of interest** that we aim to match as closely as possible.

And let $X_0$ be a $(k \times J)$ matrix collecting the values of **the same preintervention variables** for the **comparison units**.

Therefore, the difference between preintervention characteristics of the unit of interest and the synthetic control is given by the vector $X_1\ -\ X_0W$. We select the synthetic control $W^*$ that minimizes the size of this difference.

The last parameter we must define addresses our variable of interest (GDP per capita). We let $Y_{jt}$ be the variable of interest of unit $j$ at time $t$. Note that $Y_{jt}(v_m, x_{jt})$ is a function of $v_m$, the vector of covariate weights, and $x_{jt}$, the vector of observed covariates of country $j$ at period $t$.

We are now ready to derive our synthetic control.

### Deriving the Synthetic Control

First, I apply a cross-validation technique to select the appropriate weights of the predictive covariates ($v_{m}$). This technique minimizes out-of-sample prediction errors. I divide the pre-intervention period into a training period from 1990 to 2001 and a validation period from 2002 to 2005. I then select the covariate weights such that the resulting model minimizes the root mean square prediction error (RMSPE) over the validation period. The RMSPE measures the lack of fit between the path of the variable of interest for a particular country (in this case, Brazil) and its synthetic counterpart (the estimated counterfactual)^[See @abadie2015comparative and @abadie2022synthetic for details, proofs, and intuition regarding the RMSPE.].

The minimization of the RMSPE is as follows:

$$ 
\min(RMSPE)=\min((\frac{1}{T_0}\sum^{T_0}_{t=1}(Y_{1t}-\sum_{j=2}^{J+1}w^{*}_{j}Y_{jt})^{2})^{\frac{1}{2}})
$$ {#eq-xyp}

Where, for this equation, $T_0$ is the validation period and $Y_{1t}$ is the observed level of GDP per capita in Brazil (defined as $j=1$) in period $t$. This process selects the vector of covariate weights that best predict the trend of GDP per capita in Brazil during the period immediately before the dawn of the New Economic Matrix, when the unit of interest and the synthetic counterfactual are assumed to be impacted by the same determinants of the variable of interest.

I now use the set of covariate weights $v_m$ selected in the previous step and apply it to the predictor data for our comparison units. The resulting model uses the calibrated covariate weights and selects the vector of weights $W^*=(w_2,..., w_{J+1})^{'}$ that minimizes the difference between the pre-intervention characteristics of the country of interest and the synthetic control: 

$$
\min(\sum^{k}_{m=1}v_m(X_{1m}-X_{0m}W)^2)
$$ {#eq-xyp}

Choosing a particular value for $W$ is equivalent to choosing a synthetic control. This results in a synthetic control that approximates as best as mathematically possible the preintervention trend of GDP per capita in Brazil. If the resulting synthetic control has a pre-intervention GDP per capita trend that is similar to Brazil's, we will have succeeded in our goal of building a reliable counterfactual to the Brazilian economy. Thus, since our counterfactual is a reliable synthetic version of the Brazilian economy during the preintervention period, but is not exposed to the intervention of interest during the postintervention period, we are able to estimate the effect of the intervention of interest on GDP per capita in Brazil as the difference in GDP per capita levels between Brazil and its synthetic counterpart in the years following the intervention.

In mathematical terms and following the definition of $Y_{jt}$ above, the synthetic control estimator of the effect of the treatment in any post-intervention period is given by the comparison between the variable of interest for the unit of interest and the variable of interest for the synthetic control at that period. Recalling that $T_1$ is the post-intervention period, let $Y_1$ be a $(T_1\times1)$ vector collecting the post-intervention values for GDP per capita for the treated unit (Brazil). Let $Y_0$ be a $(T_1\times J)$ matrix, where column $J$ contains the post-intervention predicted values of GDP per capita for unit $J+1$. Then, the effect of the New Economic Matrix on GDP per capita in Brazil is estimated as the difference in GDP per capita levels between Brazil and its synthetic counterfactual in the years following the change in Finance Ministry, which marked the beginning of the implementation of NEM policies. Thus, now letting $T_0$ be the pre-intervention period, for any $t\geq T_0+1$, this effect is given by:

$$
Y_{1t}-\sum^{J+1}_{j=2}w^{*}_{j}Y_{jt}
$$ {#eq-xyp}

For proofs and technical details that corroborate the validity of the SCM in constructing a reliable counterfactual to our country of interest, refer to @abadie2021using; @abadie2010synthetic; @abadie2015comparative; @abadie2022synthetic; @botosaru2019role; and @ferman2020cherry.

### A Word on the Choice of Covariates and Comparison Units

The model for synthetic controls mathematically assigns weights to the comparison units and to the covariates of choice to provide the best possible approximation of the trend in the country of interest's variable of interest during the pre-intervention period. In this study, the variable of interest is PPP GDP per capita measured in constant 2017 international \$. @abadie2015comparative state that it is of crucial importance that synthetic controls closely reproduce the pre-intervention values that covariates with a large predictive power on the variable of interest take for the country affected by the intervention^[See @abadie2021using, @abadie2015comparative, and @botosaru2019role for proofs of why a perfect reproduction is not required.].

My choice of covariates (listed above) follows what @abadie2015comparative and @carrasco2014decada have defined as variables that are part of a standard set of economic growth predictors. However, in contrast to @carrasco2014decada, I opt to follow mainstream SCM literature and only include quantitative variables in my list of covariates.

Literature on the SCM highlights that the choice of our comparison units requires care. Here, the country/unit of interest is Brazil. Recall that the synthetic control derived from the comparison units is meant to approximate the counterfactual of the country of interest that is free of the impacts of the intervention. Therefore, it is important to restrict the country pool of comparison units to countries with outcomes that are thought to be driven by similar processes as for the country of interest and that were not subject to large idiosyncratic shocks that did not affect the country of interest [@abadie2015comparative].

Considering the above, my starting point for the selection of the comparison units is the IMF’s classification of Emerging and Developing Economies in the World Economic Outlook Database^[As in @carrasco2014decada, but keeping in mind that I am using the most recent classification.]. From this starting point, countries in this list were selected for the final country pool if they met one of three conditions: (1) geographic proximity and ties with the Brazilian economy, (2) sizeable population and considerable impact on the global economy, and (3) similar GDP per capita growth trends as Brazil’s in the pre-intervention period. As mentioned above, the final pool of comparison units is Bolivia, Bulgaria, Chile, China, Colombia, Costa Rica, Ecuador, Egypt, India, Iran, Mexico, Pakistan, Paraguay, Peru, Poland, South Africa, Turkey, Ukraine, and Uruguay^[Argentina and Venezuela fitted the geographic parameter but were excluded due to large idiosyncratic shocks during the study period. Indonesia, the Philippines, and Thailand have considerable populations but were excluded due to large shocks in the 1990s. Finally, Russia also has a considerable population size but was excluded due to idiosyncratic shocks and high levels of volatility in the variable of interest.].

### Main Assumption and Threats to Inference

Having defined the period of analysis, the comparison units, the covariates, and the mathematical derivation, the main assumption of the model is as follows: 

Only units that are alike in both observed and unobserved determinants of the variable of interest, as well as in the effect of those determinants upon such variable, should produce similar trajectories of the variable of interest over extended periods of time. Once it has been established that the country of interest and the synthetic control unit have similar behavior over extended periods prior to the intervention, a discrepancy in the variable of interest in the post-intervention period is interpreted as produced by the intervention itself^[See @abadie2003economic, @abadie2010synthetic, @abadie2015comparative, @abadie2021using, @abadie2022synthetic, and @botosaru2019role for proofs and in-depth explanations.].

Based on the above and the intense active discussions in academia regarding the inferential validity of synthetic controls^[See, for example, @botosaru2019role and @ferman2020cherry.], I must discuss three important considerations: 

(1) On the upside, mathematical proofs show that synthetic controls with a very close pre-intervention fit for the variable of interest between the counterfactual and the unit of interest control for the impacts of unobserved confounders. In other words, confounders that affect both Brazil and its counterfactual are taken into account in the derivation of the model. Note, however, that if another event/intervention that had its start in or around 2006 is what is actually impacting the GDP per capita trend in Brazil, we would be unable to differentiate its impact from the impact of the NEM. One variable that fits this timeline and might have had a negative impact in the Brazilian economy is the perception of the level of corruption in the country. Starting in 2005, several corruption schemes were discovered, which might have affected domestic investment, foreign direct investment, and confidence towards governmental institutions. Below, I discuss one empirical extension that can rule out the possible confounding impact of the perception of levels of corruption.

(2) If the synthetic control does not closely reproduce the pre-intervention values that covariates with a large predictive power on the variable of interest take for the country affected by the intervention and/or does not produce a similar trajectory of the variable of interest in comparison to Brazil over extended periods of time, the resulting counterfactual fails to respect the main assumptions and, therefore, cannot be used as evidence for a causal relationship. This is the case in @carrasco2014decada and @balassiano2018recessao. In both papers, the authors do not present evidence showing how well the syntehtic control reproduces the pre-intervention values of covariates. Furthermore, both papers fail to derive a counterfactual with a similar pre-intervention trajectory for the variable of interest compared to that of Brazil.

(3) Traditional exercises that test for levels of statistical significance are not possible within the framework of the SCM. This is one of the main limitations of the method. There are, however, other ways to measure the significance and robustness of the results derived with synthetic controls. Therefore, I will employ two other empirical extensions to add credibility to the inferential conclusions of the model. One will address the possibility that the final results are too reliant on any given country from the country pool, while the other investigates the significance of the results (i.e., Was the estimated size of the impact of the NEM a product of random chance?).

### Empirical Extensions

Following @abadie2010synthetic, @abadie2015comparative, and @abadie2021using, I will perform two different inference tests as empirical extensions to evaluate the credibility of my results. If my model passes these tests, this adds credibility and trustworthiness to estimated effect of the New Economic Matrix on GDP per capita calculated through Equation (3). Additionally, I discuss one additional empirical extension that takes the from of an alternative synthetic control model that measures the impact of the NEM on a different variable of interest.

#### Placebo Study

An in-space placebo study reassigns the treatment in the data to each one of the comparison units. This will allow me to obtain synthetic control estimates for countries that did not experience the event of interest, namely the New Economic Matrix. While some countries in our pool were exposed to similar versions of some of the policies related to the NEM, nowhere did the policy-making strategy embrace as many aspects of economic policy and represent such a clear break with previous trends as in Brazil.

Applying the synthetic control estimation process to each of our comparison units in the country pool allows for the comparison of the estimated effect of the NEM in Brazil to the distribution of placebo effects obtained for other countries. This is done by comparing the ratios of post-intervention RMSPE and pre-intervention RMSPE for Brazil and for all the units in the country pool. Recall that the RMSPE measures the lack of fit between the path of the variable of interest (in this case, GDP per capita) for a particular country and its synthetic counterpart. I argue that Brazil was the only country that underwent the intervention characterized by the New Economic Matrix. Therefore, the effect of the NEM on the Brazilian economy will be considered significant if the resulting RMSPE ratio for Brazil is large compared to the distribution for the placebo effects^[See @abadie2015comparative for details on RMSPE ratio placebo study.]. If successful, this test indicates that the main results were not a product of random chance.

#### Robustness Test

The objective of the robustness test is to check the sensitivity of my main results to changes in the country weights, $W^*$. I will iteratively re-estimate the model to construct a counterfactual of Brazil, omitting in each iteration one of the countries that were assigned at least 10\% weights in my main model. According to @abadie2015comparative, by excluding countries that received a large positive weight, we sacrifice some of the goodness of the pre-intervention fit, but this sensitivity check allows for the evaluation of the extent to which results are driven by any particular control country^[Also see @abadie2021using for details on the robustness test.]. If the resulting trend of the impact of the NEM is similar for all the models that create a counterfactual without using one of high weight countries in the main model, this shows that the results are robust to the exclusion of any particular country that was assigned a high predictive weight in the main counterfactual.

#### Alternative synthetic control

As mentioned above, several corruption scandals were uncovered in Brazil during the 2005-2018 period, starting with the Mensalão. These events might have led to an increase in the risk-aversion levels of domestic agents and a decrease in the willingness of foreign agents to do business in Brazil. If that was the case, then it is possible that this change in the perception of corruption levels in Brazilian governmental institutions could have impacted output levels and, by consequence, the GDP per capita trend of the country. 

The timing of these corruption scandals and the connection of Mensalão with the dawn of the New Economic Matrix might be confounding the results of the intervention in the setup utilized in this project. Applying the SCM to measure the impact of the NEM on an alternative variable of interest that would not have been impacted by the increase in the perception of corruption is a promising strategy to rule out the possibility of this confounding effect. A good candidate for the variable of interest in this alternative exercise is the Human Capital Index (HCI), calculated by the World Bank and available in both the Human Capital Index Database and the World Development Indicators Database. According to the World Bank, the HCI calculates the contributions of health and education to worker productivity. The final index score ranges from zero to one and measures the productivity as a future worker of child born today relative to the benchmark of full health and complete education. This index is calculated through the analysis of six variables that measure different components of health and educational standards in a country^[See https://datacatalog.worldbank.org/search/dataset/0038030 for details about the Human Capital Index.].

While one could argue that the HCI is not perfectly independent from the impact of changes in the perceptions of the level of corruption in a country, it is definitely less sensitive to it than GDP per capita. The variables that comprise the HCI are not as affected by an increase in the perceived level of corruption as the forces (described above) that can arguably negatively impact GDP per capita. On the other hand, if the policies of the New Economic Matrix had a negative impact in the Brazilian economy and the country's rate of development, one could expect it to negatively impact the HCI trend in Brazil.

## Findings

### The Effects of the New Economic Matrix

Here I present the results of applying the sample described in the *Data and Sample* section of the *Research Design* to the mathematical model described in the *Deriving the Synthetic Control* section of the *Research Design*.

First, let's analyze the solution to the minimization problem characterized in Equation (1). The weights that solve the cross-validation exercise above indicate that the most important predictors from our list of covariates are: GDP per capita (0.363); Agriculture, forestry, and fishing, value added (0.319); Net barter terms of trade (0.179); Unemployment (0.069); Industry (including construction), value added (0.042); Trade Openness (0.020); Inflation (0.007); and Gross capital formation (0.001). Recall that the country pool is comprised of developing countries that are similar to Brazil. Therefore, it makes sense that the GDP per capita in these countries has a high prediction power of GDP per capita in Brazil. On the other hand, one should worry if the model is too reliant on GDP per capita (for example, with a weight of 0.6 or more, which is not the case in my model). Since a good balance in terms of both covariates and pre-treatment outcomes implies tighter bounds on the bias of the synthetic control estimator, a balanced prediction across multiple covariates is preferred^[Refer to @botosaru2019role for in-depth definitions, explanations, and proofs regarding the balance of covaritates and why a perfect match between pre-intervention values of covariates for the synthetic counterfactual and the country of interest is not necessary to infer causation in the results. This is an important discussion that goes beyond the scope and length of this piece.]. Having value added of agriculture as the second-most important predictor is another positive sign, as it is one of the most important sectors in the Brazilian economy and the most relevant one in terms of exports.

I now use this vector $v_m$ of covariate weights, apply it to the predictor data in the country pool and select the vector of country weights $W^*=(w_2,..., w_{J+1})^{'}$ that solves the minimization problem characterized in Equation (2). The synthetic counterfactual of Brazil is a weighted average of Peru (0.28), South Africa (0.28), Mexico (0.23), Turkey (0.16), Pakistan (0.03), and Colombia (0.02). All other countries in the country pool obtain zero weights.

Table 3 compares the pre-NEM characteristics of Brazil to those of the synthetic counterfactual of Brazil and to those of the average of the same sample of Latin American countries used in Figures 1 and 2 for the predictors that are assigned weights of at least 2\% in the cross-validation exercise. This analysis suggests that the synthetic version of Brazil constructed by the model provides a better comparison for Brazil than the Latin American average.

```{r scm derivation, include=FALSE}
#in this chunk I perform the derivation of the main synthetic control and calculate the values to be included in table 3

#12. subsetting years of interest
#Period of choice: 1990-2016
#I will subset 1985-2018 to make it easier for me to create new versions if I want

data.v6 <- data.v6 %>% 
  filter(year >= 1985)

#13. changing index numbers
unique(data.v6$country)

data.v6.ready <- data.v6 %>% 
  mutate(index = case_when(
    country == "BGR" ~ 1,
    country == "BOL" ~ 2,
    country == "BRA" ~ 3,
    country == "CHL" ~ 4,
    country == "CHN" ~ 5,
    country == "COL" ~ 6,
    country == "CRI" ~ 7,
    country == "ECU" ~ 8,
    country == "EGY" ~ 9,
    country == "IND" ~ 10,
    country == "IRN" ~ 11,
    country == "MEX" ~ 12,
    country == "PAK" ~ 13,
    country == "PER" ~ 14,
    country == "POL" ~ 15,
    country == "PRY" ~ 16,
    country == "TUR" ~ 17,
    country == "UKR" ~ 18,
    country == "URY" ~ 19,
    country == "ZAF" ~ 20,
  ))

#checking indexes
unique(data.v6.ready$index)

#14. Mapping necessary data conditions to decide if I use special predictors
#Necessary data conditions:
#1- Variable of interest (gdpc): no NAs for any country nor year
#2- Covariates: info on at least one year for all countries

#checking condition 1
data.check.gdpc <- data.v6.ready %>% 
  filter(is.na(gdpc))

unique(data.check.gdpc$year) #no missing data on gdp per capita from 1990 onwards, perfect!

#15. Visually checking condition 2
#Here is where I decided not to use debt as one of the covariates. 
#Brazil only has debt starting in 2001, does not go up that much, 
#and I don't think its the most important predictor of gdp
#Training period for cross validation will have to go from 1990 until 2001 to fulfill condition (2) for all covariates

#16. RUNNING SCM
#In this version pre-treatment years are 1990-2006
#I am using 2006 as intervention year due to change in policy justifications and event of change in finance ministry

## pick v by cross-validation
# data setup for training model
dataprep.out.v6 <-
  dataprep(
    foo = data.v6.ready,
    predictors    = c("agva", "tradeop", "gdpc", "gcf", "indva", "infrate", "termstrade", "unemp"),
    dependent     = "gdpc",
    unit.variable = "index",
    time.variable = "year",
    treatment.identifier = "BRA",
    controls.identifier = unique(data.v6.ready$country[-which(data.v6.ready$country == "BRA")]),
    time.predictors.prior = 1990:2001, #this is training period
    time.optimize.ssr = 2002:2006, #this is validation period
    time.plot = c(1990:1994,1996:2018), #full period in the analysis 
    unit.names.variable = "country"
  )

# fit training model
synth.out.v6.prep <- 
  synth(
    data.prep.obj=dataprep.out.v6,
    Margin.ipop=.005,Sigf.ipop=7,Bound.ipop=6
  ) #this gives my solution v from cross validation used in table 2 of abadie 2015; sequence of v weights correspond to sequence in predictors argument

#also gives MSPE (LOSS V): 6586.884

#checking choices of covariate weights
names(synth.out.v6.prep)
synth.out.v6.prep$solution.v #choice of v for this version: looks pretty reasonable. Brazil is big on agriculture, so it makes sense!


# data prep for main model
dataprep.out.v6.main <-
  dataprep(
    foo = data.v6.ready,
    predictors    = c("agva", "tradeop", "gdpc", "gcf", "indva", "infrate", "termstrade", "unemp"),
    dependent     = "gdpc",
    unit.variable = "index",
    time.variable = "year",
    treatment.identifier = "BRA",
    controls.identifier = unique(data.v6.ready$country[-which(data.v6.ready$country == "BRA")]),
    time.predictors.prior = 2002:2006, #validation period (time.opt.ssr above) in cross validation (counts intervention year)
    time.optimize.ssr = 1990:2005, #full pre intervention period (DOES NOT COUNT INTERVENTION YEAR)
    time.plot = c(1990:1994,1996:2018), #full period in the analysis
    unit.names.variable = "country"
  )

#fitting main model with v from training model
synth.out.v6.main <- synth(
  data.prep.obj=dataprep.out.v6.main,
  custom.v=as.numeric(synth.out.v6.prep$solution.v)
) #this gives my w weight for each country
#my thing gives MSPE (LOSS V): 93597.19 

#17. QUICK SUMMARY CODE-----------------------------
#gaps
gaps.v6 <- dataprep.out.v6.main$Y1plot-(
  dataprep.out.v6.main$Y0plot%*%synth.out.v6.main$solution.w
)

gaps.v6

## plot the gaps (treated - synthetic)
gaps.plot(dataprep.res = dataprep.out.v6.main, synth.res = synth.out.v6.main, Ylim = c(-5800,5800)) #visualizing equation (3)
abline(v=2005 ,lty="dotted")

#tables
synth.tables.v6 <- synth.tab(
  dataprep.res = dataprep.out.v6.main,
  synth.res = synth.out.v6.main)
print(synth.tables.v6)

#result graph
## plot in levels (treated and synthetic)
path.plot(dataprep.res = dataprep.out.v6.main, 
          synth.res = synth.out.v6.main, 
          Ylim = c(3000, 20000),
          Legend.position=c("bottomright"),
          Main = "v6") #easy version of figure 2
abline(v=2005 ,lty="dotted")
#---- END of quick summary code ----#

#18. Preparing table 3

#18.1 Creating LaTam predictor means for Table 3

#selecting covariates
latam_means <- data.v6.vars.step7 %>% 
  select(index, 
         country, 
         year, 
         gdpc, 
         agva,
         termstrade,
         unemp,
         indva,
         tradeop,
         infrate,
         gcf)

#selecting countries
latam_means <- latam_means %>%
  filter(country %in% c("ARG",
                        "BOL",
                        "CHL", 
                        "COL", 
                        "CRI", 
                        "ECU", 
                        "MEX", 
                        "PRY", 
                        "PER",
                        "URY")) #original dataset has no information for venezuela

unique(latam_means$country)

#selecting years
latam_means <- latam_means %>% 
  filter(year >= 2000) %>% 
  filter(year <= 2005)

#creating average
table2.lat.avg <- aggregate(gdpc ~ year, data = latam_means, FUN = mean, na.rm = TRUE)

#agva
table2.lat.avg.ag <- aggregate(agva ~ year, data = latam_means, FUN = mean, na.rm = TRUE)

table2.lat.avg.ag.tobind <- table2.lat.avg.ag %>% 
  select(agva)

#termstrade
table2.lat.avg.termstrade <- aggregate(termstrade ~ year, data = latam_means, FUN = mean, na.rm = TRUE)

table2.lat.avg.termstrade.tobind <- table2.lat.avg.termstrade %>% 
  select(termstrade)

#unempv2
table2.lat.avg.unempv2 <- aggregate(unemp ~ year, data = latam_means, FUN = mean, na.rm = TRUE)

table2.lat.avg.unempv2.tobind <- table2.lat.avg.unempv2 %>% 
  select(unemp)

#indva
table2.lat.avg.indva <- aggregate(indva ~ year, data = latam_means, FUN = mean, na.rm = TRUE)

table2.lat.avg.indva.tobind <- table2.lat.avg.indva %>% 
  select(indva)

#tradeop
table2.lat.avg.tradeop <- aggregate(tradeop ~ year, data = latam_means, FUN = mean, na.rm = TRUE)

table2.lat.avg.tradeop.tobind <- table2.lat.avg.tradeop %>% 
  select(tradeop)

#infrate
table2.lat.avg.infrate <- aggregate(infrate ~ year, data = latam_means, FUN = mean, na.rm = TRUE)

table2.lat.avg.infrate.tobind <- table2.lat.avg.infrate %>% 
  select(infrate)

#gcfv4
table2.lat.avg.gcfv4 <- aggregate(gcf ~ year, data = latam_means, FUN = mean, na.rm = TRUE)

table2.lat.avg.gcfv4.tobind <- table2.lat.avg.gcfv4 %>% 
  select(gcf)

#binding year averages
table2.lat.avg.years <- cbind(table2.lat.avg,
                              table2.lat.avg.ag.tobind,
                              table2.lat.avg.termstrade.tobind,
                              table2.lat.avg.unempv2.tobind,
                              table2.lat.avg.indva.tobind,
                              table2.lat.avg.tradeop.tobind,
                              table2.lat.avg.infrate.tobind,
                              table2.lat.avg.gcfv4.tobind)

#calculating the means for predictors with 2% weight or more
mean(table2.lat.avg.years$gdpc) #11828.45

mean(table2.lat.avg.years$agva) #8.452563

mean(table2.lat.avg.years$termstrade) #87.10887

mean(table2.lat.avg.years$unemp) #8.845074

mean(table2.lat.avg.years$indva) #29.32424

mean(table2.lat.avg.years$tradeop) #54.06174

#18.2 calculating gdpc mean for Brazil and Synthetic Brazil
#-brazil
br.gdpc.t2 <- data.v6.ready %>% 
  select(country, year, gdpc) %>% 
  filter(country == "BRA") %>% 
  filter(year >= 2000 & year <= 2005)

mean(br.gdpc.t2$gdpc) #11887.83

#-synthetic (subtracting from gaps that results of scm derivation)
#a negative number for the gap mean brazil's gdp is lower than that of the counterfactual
#therefore, to get to the predicted counterfactual gdp, we subtract the gap from brazil's gdp for the respective years 
brsynth.gdpc.t2 <- br.gdpc.t2

brsynth.gdpc.t2$gdpc[1] <- brsynth.gdpc.t2$gdpc[1] - gaps.v6[10]
brsynth.gdpc.t2$gdpc[2] <- brsynth.gdpc.t2$gdpc[2] - gaps.v6[11]
brsynth.gdpc.t2$gdpc[3] <- brsynth.gdpc.t2$gdpc[3] - gaps.v6[12]
brsynth.gdpc.t2$gdpc[4] <- brsynth.gdpc.t2$gdpc[4] - gaps.v6[13]
brsynth.gdpc.t2$gdpc[5] <- brsynth.gdpc.t2$gdpc[5] - gaps.v6[14]
brsynth.gdpc.t2$gdpc[6] <- brsynth.gdpc.t2$gdpc[6] - gaps.v6[15]

mean(brsynth.gdpc.t2$gdpc) #11894.47

#18.3 creating df for table 3
synth.table2 <- synth.tables.v6$tab.pred[-6,]
synth.table2 <- synth.table2[-4,]

# Replace means for LaTam sample (computed externally)
synth.table2[,3]          <- c(mean(table2.lat.avg.years$agva),
                               mean(table2.lat.avg.years$tradeop),
                               mean(table2.lat.avg.years$gdpc),
                               mean(table2.lat.avg.years$indva),
                               mean(table2.lat.avg.years$termstrade),
                               mean(table2.lat.avg.years$unemp))
colnames(synth.table2)[3] <- "Latin America"
rownames(synth.table2) <- c("Agriculture, v.a.","Trade openness",
                                     "GDP per capita","Industry, v.a.",
                                     "Terms of trade","Unemployment")
synth.table2[3,1] <- mean(br.gdpc.t2$gdpc)
synth.table2[3,2] <- mean(brsynth.gdpc.t2$gdpc)

#18.4 calculating % diff between Brazil and Synthetic Brazil
#agva
agva.tab.diff <- abs(round(((synth.table2[1,1]-synth.table2[1,2])/synth.table2[1,2]),4)*100)
agva.tab.diff #8.47

#tradeopen
tradeop.tab.diff <- abs(round(((synth.table2[2,1]-synth.table2[2,2])/synth.table2[2,2])*100,2))
tradeop.tab.diff #40.96

#gdpc
gdpc.tab.diff <- abs(round(((synth.table2[3,1]-synth.table2[3,2])/synth.table2[3,2])*100,2))
gdpc.tab.diff #0.06

#indva
indva.tab.diff <- abs(round(((synth.table2[4,1]-synth.table2[4,2])/synth.table2[4,2])*100,2))
indva.tab.diff #19.71

#ttrade
ttrade.tab.diff <- abs(round(((synth.table2[5,1]-synth.table2[5,2])/synth.table2[5,2])*100,2))
ttrade.tab.diff #0.28

#unemp
unemp.tab.diff <- abs(round(((synth.table2[6,1]-synth.table2[6,2])/synth.table2[6,2])*100,2))
unemp.tab.diff #7.07

#creating column for % diff
synth.table2 <- as.data.frame(synth.table2)
synth.table2 <- synth.table2 %>% 
  mutate(pct.diff = c(agva.tab.diff, 
                      tradeop.tab.diff,
                      gdpc.tab.diff,
                      indva.tab.diff,
                      ttrade.tab.diff,
                      unemp.tab.diff))
#creating variable name column
synth.table2 <- synth.table2 %>% 
  mutate(vars = c("Agriculture, v.a.",
                  "Trade openness",
                  "GDP per capita",
                  "Industry, v.a.",
                  "Terms of trade",
                  "Unemployment"))

#-putting in ideal row and column order

#ideal column order
synth.table2.ready <- synth.table2 %>% 
  select(vars, Treated, Synthetic, pct.diff, `Latin America`)

#ideal row order (in decreasing v, weight)
synth.table2.ready.f <- synth.table2.ready[c(3, 1, 5, 6, 4, 2),]

#rounding to facilitate visualization
synth.table2.ready.f$Synthetic <- round(synth.table2.ready.f$Synthetic,1)
synth.table2.ready.f$Treated <- round(synth.table2.ready.f$Treated,1)
synth.table2.ready.f$`Latin America` <- round(synth.table2.ready.f$`Latin America`,1)

```

```{r table 3, echo=FALSE, results='markup', fig.cap="<span style='font-size: smaller; color: gray;'>Table 3. Notes: Rounded averages for the 2000-2005 period. The Difference column represents the percentage difference between the estimated averages for the Synthetic Control and the averages for Brazil."}
#19. creating table 3
synth.table2.ready.f <- synth.table2.ready.f %>%
  rownames_to_column(var = "row_number")

synth.table2.ready.f <- synth.table2.ready.f %>% 
  select(!row_number)

t3 <- synth.table2.ready.f %>%
  kbl(caption="Economic Growth Predictor Means for Pre-NEM Period",
      format= "html", #we can change this to "latex" and delete "Table 1" to title (latex automatically includes table count)      
      col.names = c("","Brazil", "Synthetic Brazil", "% Difference", "Latin America"),
      align = c("l", "r", "r", "r", "r"), #if align = NULL, numeric columns are right-aligned, and other columns are left-aligned
      longtable = T,
      tabular = "longtable",
      digits = 2,
      booktabs = T) %>% 
  kable_classic(full_width = F, html_font = "helvetica")
t3
```

Furthermore, Table 3 shows that my synthetic control respects one of the most important necessary validity conditions for the method mentioned in point (2) of the *Main Assumption and Threats to Inference* section of the *Research Design*. The model very closely reproduces the 2000-2005 average for the covariates with the four largest predictive powers derived in the cross-validation, namely GDP per capita, value added of Agriculture, Net Barter Terms of Trade, and Unemployment.

Figure 3 summarizes the main results of this project. It displays the GDP per capita trajectory of Brazil and its synthetic counterfactual for the 1990-2018 period. The counterfactual constructed in the model very closely reproduces the GDP per capita trend during the pre-intervention years. While there is some lack of fit during the 1990-1997 period, the model demonstrates the same trends and characteristics as the Brazilian economy from 1998 until the end of the pre-intervention period. This trend, paired with the close fit of Table 3 and the satisfactory results of the inference tests below, demonstrates that there exists a combination of other developing economies that reproduces the economic attributes of Brazil before the advent of the NEM. This indicates that the model represents a reliable counterfactual that was not exposed to the New Economic Matrix. 

```{r graph 3, echo=FALSE, results='markup', fig.cap='Figure 3'}
#20. Here I construct the graph for the main result in my synthetic control study, derived in step 16 above
Text.height <- 7000
Cex.set <- .8
years <- 1990:2018

synthY0 <- (dataprep.out.v6.main$Y0%*%synth.out.v6.main$solution.w)
plot(c(1990:1994,1996:2018),dataprep.out.v6.main$Y1plot,
     type="l",ylim=c(3000,20000),col="green",
     lty="solid",
     ylab ="Per-Capita GDP, PPP (2017 int. $)",
     xlab ="Year",
     xaxs = "i", yaxs = "i",
     lwd=2,
     xaxt = "n",
     main = "Trends in GDP per Capita: Brazil vs. Synthetic Brazil"
)
axis(1, at = years[seq(1, length(years), by = 3)], labels = years[seq(1, length(years), by = 3)])
lines(c(1990:1994,1996:2018),synthY0,col="black",lty="dashed",lwd=2)
abline(v=2005,lty="dotted")
legend(x="bottomright",
       legend=c("Brazil","Synthetic Brazil")
       ,lty=c("solid","dashed"),col=c("green","black")
       ,cex=.8,bg="white",lwd=c(2,2))
arrows(2004,Text.height,2004.8,Text.height,col="black",length=.1)
text(1999.6,Text.height,"End of Pre-intervention Period",cex=Cex.set)
```

My estimate of the effect of the New Economic Matrix in Brazil is given by the difference between the Brazilian trend and its counterfactual in the post-intervention period. The gap between the post-intervention trends is a visual representation of Equation 3. The NEM policies did not have much of an effect in the first two years after Mantega’s rise to the Finance Ministry, and Brazil even outperformed its counterfactual in the aftermath of the global financial crisis. This is in line with the arguments of @werneck2014alternancia, who states that expansionary fiscal policies artificially generated a demand boom in the early 2010s. The author affirms that this created a lag until the constraints in supply, low productivity, lack of infrastructure, low external competitiveness, and a rising tax burden evidenced the shortcomings of policies associated with the New Economic Matrix. My results support this and the findings of other authors discussed in the *Introduction*. Following @abadie2015comparative, the estimated effect of the intervention is computed as the percentage difference between the GDP per capita in the country of interest and the GDP per capita of its synthetic counterfactual in the last sample period. In 2018, GDP per capita in the synthetic counterfactual of Brazil – that was not exposed to the policies of the NEM – is estimated to be about 16.5\% higher than in the actual Brazil. In other words, according to this model, GDP per capita in Brazil would have been about 2,400 USD higher in 2018, had the New Economic Matrix not been implemented.

## Empirical Extensions

I now present the results of two of the empirical extensions. Furthermore, I discuss the constraints that impeded the calculation of the third empirical extension at this moment, which, by consequence, points to the next steps of my research on the topic of this project.

### Placebo Study

Figure 4 shows the post-intervention and pre-intervention root mean square prediction error ratio for Brazil and each country in the country pool. Countries with positive weights in the synthetic control are highlighted in red. Brazil clearly stands out as the country with the highest RMSPE ratio. Brazil's post-intervention gap is about five times larger than the pre-intervention gap, which represents a ratio that is 125\% larger than the average ratio for placebo effects. Therefore, based on the above explanation of the Placebo Study, the test suggests that the effect of the NEM on the Brazilian economy is indeed considered significant.

```{r placebo study, include=FALSE}
#21. Coding/calculating the Placebo Study test

#looping across control units
storegaps <- #nrow is number of years, ncol is number of control countries
  matrix(NA,
         length(c(1990:1994,1996:2018)),
         length(unique(data.v6.ready$index))-1 #-1 to take country of interest out 
  )
rownames(storegaps) <- c(1990:1994,1996:2018) #naming the rows of the dataset created above
i <- 1
co <- unique(data.v6.ready$index) 

for(k in unique(data.v6.ready$index) [-3]){ #-3 to cut Brazil, since we calculated its gaps above
  
  # data prep for training model
  dataprep.out <-
    dataprep(
      foo = data.v6.ready,
      predictors    = c("agva", "tradeop", "gdpc", "gcf", "indva", "infrate", "termstrade", "unemp"),
      dependent     = "gdpc",
      unit.variable = 1,
      time.variable = 3,
      treatment.identifier = k, #country to be used as interest in each loop
      controls.identifier = co[-which(co==k)], #cutting country of interest in each loop out of country pool
      time.predictors.prior = 1990:2001, #this is training period
      time.optimize.ssr = 2002:2006, #this is validation period
      unit.names.variable = 2,
      time.plot = c(1990:1994,1996:2018), 
    )
  
  # fit training model
  synth.out.t <-
    synth(
      data.prep.obj=dataprep.out,
      Margin.ipop=.005,Sigf.ipop=7,Bound.ipop=6
    )
  
  # data prep for main model
  dataprep.out <-
    dataprep(
      foo = data.v6.ready,
      predictors    = c("agva", "tradeop", "gdpc", "gcf", "indva", "infrate", "termstrade", "unemp"),
      dependent     = "gdpc",
      unit.variable = 1,
      time.variable = 3,
      treatment.identifier = k,
      controls.identifier = co[-which(co==k)],
      time.predictors.prior = 2002:2006, #validation period (time.opt.ssr there) in cross validation (counts intervention year)
      time.optimize.ssr = 1990:2005, #full pre intervention period (DOES NOT COUNT INTERVENTION YEAR)
      unit.names.variable = 2,
      time.plot = c(1990:1994,1996:2018), 
    )
  
  # fit main model
  synth.out <- synth(
    data.prep.obj=dataprep.out,
    custom.v=as.numeric(synth.out.t$solution.v)
  )
  
  storegaps[,i] <-  
    dataprep.out$Y1plot-
    (dataprep.out$Y0plot%*%synth.out$solution.w) #so each column in storegaps is the equivalent of each country of gaps.v6 for brazil
  i <- i + 1
} # close loop over control units
d <- data.v6.ready[order(data.v6.ready$index,data.v6.ready$year),]
colnames(storegaps) <- unique(d$country)[-3]
storegaps <- cbind(gaps.v6,storegaps) #binding gap for Brazil with gap for others
colnames(storegaps)[1] <- c("BRA")

# compute ratio of post-reunification RMSPE 
# to pre-reunification RMSPE                                                  
rmse <- function(x){sqrt(mean(x^2))}
preloss <- apply(storegaps[1:15,],2,rmse) #the two here indicates that should perform operation in the columns
postloss <- apply(storegaps[16:28,],2,rmse)
colors.rmspe <- c("black",
                  "red",
                  "black",
                  "black",
                  "black",
                  "black",
                  "black",
                  "black",
                  "black",
                  "red",
                  "black",
                  "red",
                  "black",
                  "black",
                  "red",
                  "black",
                  "red",
                  "black",
                  "red",
                  "black")

rmspe.ratio <- sort(postloss/preloss)

#calculating mean and comparing to brazil
ratio.pool <- sort(postloss/preloss)
ratio.pool <- ratio.pool[-20]
mean(ratio.pool)
percentage.diff <- (sort(postloss/preloss)[20]-mean(ratio.pool))/mean(ratio.pool)

```

```{r graph 4, echo=FALSE, results='markup', fig.cap='Figure 4'}
#21. Generating figure 4 presenting placebo study results
dotchart(rmspe.ratio,
         xlab="Post-intervention RMSPE / Pre-intervenion RMSPE",
         pch=15,
         col = colors.rmspe,
         main = "Ratio of Post-intervention RMSPE to\nPre-intervention RMSPE for Brazil and Control Countries")

```

### Robustness Test

For the Robustness test, I iteratively re-estimate the model to construct a counterfactual of Brazil, omitting in each iteration one of the countries that were assigned at least 10\% weights in my main model, namely Peru, South Africa, Mexico, and Turkey.

```{r robustness test, include=FALSE}
#22. Coding/calculating robustness test

# looping over leave one outs (only leaving out guys with 10%+ weight) _ KEEP THIS
storegaps.rob <- 
  matrix(NA,
         length(c(1990:1994,1996:2018)),
         4)
colnames(storegaps.rob) <- c(12,14,17,20) #leave out the countries that were given positive weights in main result
co.rob <- unique(data.v6.ready$index)[-3]

for(k in 1:4){
  
  # data prep for training model
  omit <- c(12,14,17,20)[k]  
  dataprep.out.t.rob <-
    dataprep(
      foo = data.v6.ready,
      predictors    = c("agva", "tradeop", "gdpc", "gcf", "indva", "infrate", "termstrade", "unemp"),
      dependent     = "gdpc",
      unit.variable = 1,
      time.variable = 3,
      treatment.identifier = 3,
      controls.identifier = co.rob[-which(co.rob==omit)],
      time.predictors.prior = 1990:2001, #this is training period
      time.optimize.ssr = 2002:2006, #this is validation period
      unit.names.variable = 2,
      time.plot = c(1990:1994,1996:2018)
    )
  
  # fit training model
  synth.out.t.rob <- synth(
    data.prep.obj=dataprep.out.t.rob,
    Margin.ipop=.005,Sigf.ipop=7,Bound.ipop=6
  )
  
  # data prep for main model
  dataprep.out.m.rob <-
    dataprep(
      foo = data.v6.ready,
      predictors    = c("agva", "tradeop", "gdpc", "gcf", "indva", "infrate", "termstrade", "unemp"),
      dependent     = "gdpc",
      unit.variable = 1,
      time.variable = 3,
      treatment.identifier = 3,
      controls.identifier = co.rob[-which(co.rob==omit)],
      time.predictors.prior = 2002:2006,
      time.optimize.ssr = 1990:2005,
      unit.names.variable = 2,
      time.plot = c(1990:1994,1996:2018)
    )
  
  # fit main model 
  synth.out.m.rob <- synth(
    data.prep.obj=dataprep.out.m.rob,
    custom.v=as.numeric(synth.out.t.rob$solution.v)
  )
  storegaps.rob[,k] <- (dataprep.out.m.rob$Y0%*%synth.out.m.rob$solution.w)
} # close loop over leave one outs


```

```{r graph 5, echo=FALSE, results='markup', fig.cap='Figure 5'}
#22. Generating figure 5 presenting robustness test results
synthY0 <- (dataprep.out.v6.main$Y0%*%synth.out.v6.main$solution.w)
plot(c(1990:1994,1996:2018),dataprep.out.v6.main$Y1plot,
     type="l",ylim=c(3000,20000),col="green",lty="solid",
     ylab ="Per-Capita GDP, PPP (2017 int. $)",
     xlab ="Year",
     xaxs = "i", yaxs = "i",
     lwd=2,
     xaxt = "n",
     main = "Leave-One-Out Distribution of the Synthetic Control for Brazil"
)
axis(1, at = years[seq(1, length(years), by = 3)], labels = years[seq(1, length(years), by = 3)])
lines(c(1990:1994,1996:2018),synthY0,col="black",lty="dashed",lwd=2)
abline(v=2005,lty="dotted")
arrows(2004,Text.height,2004.8,Text.height,col="black",length=.1)
text(1999.6,Text.height,"End of Pre-intervention Period",cex=Cex.set)
lines(c(1990:1994,1996:2018),storegaps.rob[,1],col="orange",lty="solid")
lines(c(1990:1994,1996:2018),storegaps.rob[,2],col="royalblue3",lty="solid")
lines(c(1990:1994,1996:2018),storegaps.rob[,3],col="indianred3",lty="solid")
lines(c(1990:1994,1996:2018),storegaps.rob[,4],col="slategray4",lty="solid")
legend(x="topleft",
       legend=c("Brazil",
                "Synthetic Brazil",
                "Synthetic Brazil (leave-one-out: Mexico)",
                "Synthetic Brazil (leave-one-out: Peru)",
                "Synthetic Brazil (leave-one-out: Turkey)",
                "Synthetic Brazil (leave-one-out: South Africa)")
       ,lty=c("solid","dashed","solid","solid","solid","solid"),col=c("green",
                                              "black",
                                              "orange",
                                              "royalblue3",
                                              "indianred3",
                                              "slategray4")
       ,cex=.8,bg="white",lwd=c(2,2,1))

```

Figure 5 reproduces the results in Figure 3 while also incorporating the estimates that exclude – in each iteration – one of the countries mentioned above from the country pool. This shows that the results presented in the *Findings* are robust to the exclusion of any particular country that was assigned a high predictive weight in my main model. The result of this test adds credibility to my results and rules out a limitation (i.e., results being mostly driven by a particular control country) that is presented in part of the SCM-based literature that studies Brazil as the country of interest. @carrasco2014decada, for example, derive a synthetic control with a much worse pre-intervention fit than the one presented here. Furthermore, their synthetic control heavily depends on Turkey (with a 0.577 weight). While the authors do not run a robustness test, it is likely that their results would not be robust to the exclusion of Turkey in the leave-one-out exercise. Conversely, in the case of the results presented here, the leave-one-out models estimate a similar negative effect of the New Economic Matrix on Brazil’s GDP per capita at the end of the sample period.

### Alternative Synthetic Control

The mathematical derivation of synthetic controls has very strict necessary conditions for data availability. For the variable of interest, the model can only be derived if there are no missing values across any of the countries in the sample (country of interest and all comparison units), across all the periods used in the analysis. Unfortunately, Human Capital Index is not reported on a yearly basis by the World Bank^[See https://data.worldbank.org/indicator/HD.HCI.OVRL?locations=BR]. The variables that generate the HCI are, however, more easily retrievable on a yearly or at least bi-yearly basis. The downside is that this would require a big effort of data merging and even more manual data collection, since the yearly information for the variables that generate the HCI can be retrieved from a number of national, institutional, and regional datasets, while the World Bank datasets are still full of missing values (NAs) for these variables when it comes to most of the countries in the sample of this study. Furthermore, as highlighted in the literature, the validity of synthetic controls depends on the usage of a large number of pre-intervention periods. It becomes increasingly harder to calculate the HCI for some countries as one goes back in time, due to limited data availability for our pool of developing sample units. Many countries in this sample lacked decent data collection efforts on variables relating to education and health before the 2000s.

For this reason, and due to the time constraints related to the submission deadline of this version of the project, this alternative synthetic control exercise will be the focus of the next steps of my research on this topic. The next steps in the endeavor to complete this empirical extension are: 

(1) Find the most complete country-year HCI dataset available.

(2) Collect HCI or HCI component variables for missing observations of each country in national or regional datasets.

(3) Calculate HCI for country-years for which only the HCI componets were available.

(4) Merge the newly calculated and collected HCI data with the dataset described in (1).

(5) Define a list of appropriate covariates for HCI.

(6) Finally, derive the synthetic control that will estimate the counterfactual for the HCI trend in Brazil.

## Discussion and Policy Implications

This project attempts to quantify the impact of the New Economic Matrix policies on Brazilian GDP per capita. My results show that, in the aggregate, the NEM had significantly large negative effects on the Brazilian economy. My model generates a good pre-intervention fit for our counterfactual and presents results that demonstrate high credibility with respect to the inference tests for the synthetic control method. Based on the two empirical extensions above, Table 3, and fulfillment of all the main requirement and assumptions of the SCM, the results are conclusive and present strong evidence supporting my initial hypothesis.

While developing economies provide challenges in terms of data availability and trend volatility compared to synthetic control studies that analyze developed countries, such as @abadie2015comparative, my research demonstrates the validity and usefulness of applying the synthetic control method in case studies of developing countries. Furthermore, this project shows more robust results than other synthetic control studies that analyze Brazil as the unit of interest^[@balassiano2018recessao and @carrasco2014decada, for example.].

My results are in line with the previous literature on the recent underperformance of the Brazilian economy. I argue that the overall impacts of the policy-making strategy that came to be defined as the New Economic Matrix not only kept Brazil from completing its so-called take-off but also, at the very least, contributed to one of the most severe economic crises in the country’s history. At most, the NEM was one of the main causes of the crisis. In terms of policy implications, this suggests that the post-2005 interventionist economic policy-making strategy did not bear fruits in the long term. While economic policy in democracies is and should continue to be partially restrained and dictated by the political pendulum, policy-makers cannot forget that economic policy strategies must be based on data and evidence. Furthermore, even though government intervention is a necessary condition of any successful economy, one should keep in mind that adding a large number of market distortions while weakening regulatory agencies (as was the case in the NEM) is a risky strategy. With that being said, this study only analyzes the NEM as a whole, and more granular approaches in future research are needed in order to distinguish the good from the bad in the long list of policies that fall within the New Economic Matrix.

